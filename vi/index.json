[{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/4-eventparticipated/4.1-event1/","title":"Sự kiện 2","tags":[],"description":"","content":"Báo cáo tổng hợp: “AWS Well-Architected Security Pillar” Mục tiêu sự kiện Đi sâu vào 5 trụ cột cốt lõi của Bảo mật AWS: IAM, Phát hiện, Bảo vệ Hạ tầng, Bảo vệ Dữ liệu và Ứng phó Sự cố. Hiểu các nguyên tắc bảo mật hiện đại: Zero Trust, Đặc quyền tối thiểu (Least Privilege) và Phòng thủ theo chiều sâu (Defense in Depth). Học cách tự động hóa kiểm tra bảo mật và phản hồi sự cố bằng các công cụ AWS native. Nhận diện các mối đe dọa đám mây phổ biến tại thị trường Việt Nam và cách giảm thiểu. Điểm nổi bật chính Mở đầu \u0026amp; Nền tảng Bảo mật Nguyên tắc cốt lõi: Chuyển từ bảo mật chu vi sang Phòng thủ theo chiều sâu, kiến trúc Zero Trust, và thực thi nghiêm ngặt Đặc quyền tối thiểu. Mô hình Trách nhiệm Chia sẻ: Làm rõ những gì AWS bảo mật (của đám mây) so với những gì khách hàng bảo mật (trong đám mây). Bối cảnh địa phương: Thảo luận về các mối đe dọa an ninh hàng đầu nhắm vào môi trường cloud tại Việt Nam. Pillar 1: Quản lý Định danh \u0026amp; Truy cập (IAM) Kiến trúc IAM hiện đại: Chuyển từ thông tin xác thực dài hạn (IAM Users) sang thông tin xác thực tạm thời (IAM Roles). Quản trị: Sử dụng IAM Identity Center cho SSO và quản lý tập trung. Kiểm soát: Triển khai SCPs và ranh giới quyền hạn (permission boundaries) cho môi trường multi-account. Best Practices: Bắt buộc dùng MFA, xoay vòng credential định kỳ và dùng Access Analyzer để xác thực chính sách. Pillar 2: Phát hiện \u0026amp; Giám sát liên tục Chiến lược ghi nhật ký: Tiếp cận theo hướng \u0026ldquo;Log everything\u0026rdquo; sử dụng CloudTrail (cấp tổ chức), VPC Flow Logs, và log của ALB/S3. Phát hiện mối đe dọa: Sử dụng Amazon GuardDuty để phát hiện mối đe dọa thông minh. Tập trung hóa: Tổng hợp các phát hiện trong AWS Security Hub. Detection-as-Code: Tự động hóa cảnh báo bằng Amazon EventBridge. Pillar 3: Bảo vệ Hạ tầng An ninh mạng: Phân đoạn VPC chặt chẽ và phân biệt rõ ràng giữa subnet private và public. Tường lửa: Hiểu về phòng thủ nhiều lớp sử dụng WAF (Web Application Firewall), AWS Shield (DDoS), và Network Firewall. Kiểm soát truy cập: Phân biệt giữa tường lửa Stateful (Security Groups) và Stateless (NACLs). Pillar 4: Bảo vệ Dữ liệu Chiến lược mã hóa: At-rest (lưu trữ): Mã hóa S3 buckets, EBS volumes, RDS, và DynamoDB. In-transit (truyền tải): Thực thi TLS/SSL. Quản lý khóa: Quản lý khóa qua AWS KMS, tập trung vào chính sách cấp quyền (grants) và xoay vòng khóa. Quản lý bí mật: Loại bỏ credential cứng trong code bằng cách sử dụng Secrets Manager và Systems Manager Parameter Store. Pillar 5: Ứng phó Sự cố (IR) Vòng đời IR: Chuẩn bị -\u0026gt; Phát hiện \u0026amp; Phân tích -\u0026gt; Ngăn chặn, Loại bỏ \u0026amp; Khôi phục -\u0026gt; Hoạt động sau sự cố. Tự động hóa: Sử dụng AWS Lambda và Step Functions để tự động khắc phục (ví dụ: cách ly EC2 bị nhiễm mã độc). Playbooks: Đi qua các kịch bản phản ứng tiêu chuẩn như \u0026ldquo;Lộ khóa IAM\u0026rdquo;, \u0026ldquo;Lộ lọt S3 Public\u0026rdquo;, và \u0026ldquo;Phát hiện mã độc\u0026rdquo;. Bài học chính Định danh là Chu vi bảo mật mới Quản lý định danh là tuyến phòng thủ quan trọng nhất. Access key dài hạn là rủi ro lớn; việc sử dụng IAM Roles và SSO là bắt buộc đối với kiến trúc hiện đại. Khả năng quan sát là Tối quan trọng Bạn không thể bảo vệ những gì bạn không thấy. Bật ghi log tập trung (CloudTrail, Config) và phát hiện mối đe dọa (GuardDuty) là bước đầu tiên trong mọi chiến lược bảo mật. Tự động hóa Bảo mật Con người thì chậm chạp; tấn công thì nhanh chóng. Các phản ứng bảo mật (khóa user, chặn IP) nên được tự động hóa qua code (Lambda/EventBridge) bất cứ khi nào có thể. Áp dụng vào công việc Kiểm tra Chính sách IAM: Rà soát quyền hạn hiện tại để đảm bảo \u0026ldquo;Least Privilege\u0026rdquo; và xóa các IAM User không sử dụng. Bật GuardDuty: Kích hoạt GuardDuty ở region chính để phát hiện bất thường ngay lập tức. Mã hóa Dữ liệu: Đảm bảo tất cả S3 bucket và EBS volume mới đều được bật mã hóa mặc định qua KMS. Xây dựng IR Playbooks: Soạn thảo kế hoạch Ứng phó sự cố cơ bản cho kịch bản \u0026ldquo;S3 bị lộ public\u0026rdquo; và \u0026ldquo;Lộ lọt thông tin xác thực\u0026rdquo;. Trải nghiệm sự kiện Buổi workshop \u0026ldquo;AWS Well-Architected Security Pillar\u0026rdquo; là một phiên làm việc buổi sáng chuyên sâu và tập trung cao độ. Nó cung cấp một cách tiếp cận có cấu trúc về bảo mật, điều thường bị bỏ qua trong các chu kỳ phát triển vội vã.\nHiểu sâu về \u0026ldquo;Defense in Depth\u0026rdquo; Phần về Bảo vệ Hạ tầng đã làm rõ cách phân lớp các kiểm soát bảo mật (WAF -\u0026gt; NACL -\u0026gt; SG) để nếu một lớp thất bại, các lớp khác vẫn hoạt động. Tập trung thực tế vào Tự động hóa Việc xem \u0026ldquo;Mini Demo\u0026rdquo; về xác thực chính sách IAM và mô phỏng truy cập rất hữu ích. Nó cho thấy bảo mật có thể được kiểm thử giống như code phần mềm. Phần Ứng phó Sự cố đã thay đổi quan điểm của em: thay vì thức dậy lúc 3 giờ sáng để sửa lỗi thủ công, chúng ta có thể viết Lambda function để khoanh vùng mối đe dọa tự động. Bối cảnh Việc nghe về các sai lầm phổ biến tại doanh nghiệp Việt Nam giúp em liên hệ các khái niệm lý thuyết với những rủi ro thực tế mà doanh nghiệp chúng em đối mặt hàng ngày. "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/4-eventparticipated/4.2-event2/","title":"Sự kiện 1","tags":[],"description":"","content":"Báo cáo tổng hợp: “DevOps trên AWS” Mục tiêu sự kiện Hiểu rõ tư duy DevOps, văn hóa và các chỉ số hiệu suất quan trọng (DORA). Làm chủ chuỗi công cụ CI/CD của AWS để chuyển giao phần mềm tự động. Nắm vững nguyên lý Infrastructure as Code (IaC) sử dụng CloudFormation và CDK. Khám phá các chiến lược container hóa và các thực hành tốt nhất về giám sát (observability) trên AWS. Điểm nổi bật chính Văn hóa DevOps và Các chỉ số quan trọng Thay đổi tư duy: Chuyển dịch từ việc làm việc biệt lập (silos) sang trách nhiệm chia sẻ giữa đội ngũ Phát triển (Dev) và Vận hành (Ops). Các chỉ số cốt lõi (DORA): Tập trung vào Tần suất triển khai (Deployment Frequency), Thời gian dẫn (Lead Time for Changes), Thời gian trung bình để khôi phục (MTTR), và Tỷ lệ lỗi khi thay đổi (Change Failure Rate). Lợi ích: Đổi mới nhanh hơn, độ tin cậy cao hơn và cải thiện sự cộng tác. Dịch vụ AWS DevOps – Quy trình CI/CD Chúng em đã khám phá quy trình tự động hóa toàn diện, chuyển từ triển khai thủ công sang điều phối tự động:\nQuản lý mã nguồn (Source Control): Sử dụng AWS CodeCommit và áp dụng các chiến lược Git như GitFlow hoặc Trunk-based. Xây dựng \u0026amp; Kiểm thử (Build \u0026amp; Test): Sử dụng AWS CodeBuild để biên dịch mã nguồn, chạy kiểm thử và đóng gói phần mềm. Chiến lược triển khai: Thực hiện AWS CodeDeploy với các cập nhật Blue/Green, Canary, và Rolling để giảm thiểu thời gian chết (downtime). Điều phối (Orchestration): Kết nối tất cả các khâu lại với nhau bằng AWS CodePipeline. Cơ sở hạ tầng dưới dạng mã (IaC) Chuyển đổi từ việc click chuột thủ công trên console sang định nghĩa hạ tầng bằng mã:\nAWS CloudFormation: Sử dụng template JSON/YAML để định nghĩa tài nguyên, quản lý các stack và phát hiện sai lệch hạ tầng (drift detection). AWS CDK (Cloud Development Kit): Định nghĩa tài nguyên đám mây bằng các ngôn ngữ lập trình quen thuộc (Python, TypeScript, Java) để tạo ra các cấu trúc tái sử dụng được. Lựa chọn công cụ: Thảo luận khi nào nên dùng template khai báo (CloudFormation) so với mã mệnh lệnh (CDK). Dịch vụ Container trên AWS Căn bản về Docker: Đóng gói ứng dụng thành các container nhẹ và linh hoạt. Registry: Sử dụng Amazon ECR để lưu trữ image an toàn và quét lỗ hổng bảo mật. Điều phối (Orchestration): So sánh giữa Amazon ECS (đơn giản, thuần AWS) và Amazon EKS (dịch vụ Kubernetes được quản lý) để mở rộng microservices. App Runner: Dịch vụ được quản lý hoàn toàn dành cho các nhà phát triển muốn triển khai container mà không cần quản lý bộ điều phối. Giám sát \u0026amp; Khả năng quan sát (Observability) CloudWatch: Trung tâm của các chỉ số (metrics), nhật ký (logs), cảnh báo (alarms) và bảng điều khiển vận hành. AWS X-Ray: Cung cấp khả năng truy vết phân tán (distributed tracing) để xác định các nút thắt hiệu năng trong kiến trúc microservices. Best Practices: Thiết lập các cảnh báo khả thi và quy trình trực chiến (on-call). Bài học chính Tư duy DevOps Văn hóa hơn Công cụ: Công cụ là thiết yếu, nhưng văn hóa cộng tác và sự an toàn tâm lý là điều kiện tiên quyết để DevOps thành công. Đo lường mọi thứ: Bạn không thể cải thiện những gì bạn không đo lường. Các chỉ số DORA là tiêu chuẩn vàng cho tốc độ và sự ổn định. Triển khai kỹ thuật Tự động hóa mọi thứ: Từ cung cấp hạ tầng (IaC) đến triển khai mã (CI/CD), các quy trình thủ công cần được loại bỏ. Cơ sở hạ tầng bất biến (Immutable Infrastructure): Coi máy chủ như gia súc thay vì thú cưng (cattle vs pets), sử dụng container và cung cấp tự động. Shift Left (Dịch chuyển sang trái): Tích hợp kiểm thử và bảo mật ngay từ đầu quy trình (CodeBuild) thay vì đợi đến cuối. Vận hành hiện đại Observability là bắt buộc: Chỉ biết hệ thống \u0026ldquo;bị sập\u0026rdquo; là chưa đủ; bạn phải biết \u0026ldquo;tại sao\u0026rdquo; thông qua tracing và logs. Triển khai lũy tiến (Progressive Delivery): Sử dụng Canary hoặc Blue/Green để giảm thiểu phạm vi ảnh hưởng (blast radius) khi cập nhật. Áp dụng vào công việc Triển khai CI/CD Pipeline: Chuyển quy trình triển khai thủ công hiện tại sang AWS CodePipeline. Áp dụng IaC: Bắt đầu định nghĩa hạ tầng cốt lõi bằng AWS CDK để kiểm soát phiên bản và khả năng tái lập tốt hơn. Container hóa Microservices: Tái cấu trúc (Refactor) các dịch vụ cũ thành Docker container và triển khai qua ECS để mở rộng tốt hơn. Tăng cường Observability: Tích hợp AWS X-Ray vào ứng dụng để truy vết các request qua các dịch vụ. Thiết lập chỉ số DORA: Bắt đầu theo dõi tần suất triển khai và MTTR để đánh giá hiệu suất của nhóm. Trải nghiệm sự kiện Tham dự hội thảo “DevOps on AWS” là một trải nghiệm mang tính chuyển đổi, giúp em thu hẹp khoảng cách giữa lý thuyết DevOps và việc triển khai thực tế trên AWS. Những trải nghiệm chính bao gồm:\nHòa mình vào Văn hóa DevOps Phiên buổi sáng đã làm rõ rằng DevOps không chỉ là một chức danh công việc mà là một phương pháp luận. Hiểu về chỉ số DORA đã cho em một khung cụ thể để đánh giá hiệu quả của chính nhóm mình. Thực hành xây dựng Pipeline Việc đi qua một bản demo CI/CD pipeline đầy đủ là điểm nhấn. Chứng kiến việc commit code kích hoạt quá trình build, chạy test và triển khai qua chiến lược Blue/Green đã chứng minh sức mạnh của tự động hóa. em đã hiểu rõ hơn về các chiến lược Git, cụ thể là khi nào nên dùng GitFlow so với Trunk-based cho quy mô nhóm hiện tại. Làm sáng tỏ Infrastructure as Code Sự so sánh giữa CloudFormation và CDK thực sự mở mang tầm mắt. Mặc dù em đã hiểu về template, nhưng việc thấy sức mạnh của CDK trong việc sử dụng logic và vòng lặp để tạo hạ tầng đã thay đổi cách em lên kế hoạch cung cấp tài nguyên trong tương lai. Đi sâu vào Container và Observability Phiên thảo luận về ECS so với EKS đã giúp giải quyết các tranh luận nội bộ về việc nên chọn bộ điều phối nào. Việc thấy AWS X-Ray trực quan hóa một truy vết phân tán làm em nhận ra hệ thống production hiện tại của chúng em đang thiếu khả năng quan sát đến mức nào. Kết nối và Hỏi đáp Phiên Q\u0026amp;A về lộ trình sự nghiệp và chứng chỉ đã cung cấp một bản đồ rõ ràng cho sự phát triển chuyên môn. Thảo luận về việc quản lý sự cố (postmortems) với "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Lại Hoàng Minh Phúc\nSố điện thoại: 0335829579\nEmail: phuclhmse184914@fpt.edu.vn\nTrường: Đại học FPT HCM\nNgành: Trí Tuệ Nhân Tạo\nLớp: AWS\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 08/09/2025 đến ngày 14/12/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"Volkswagen và AWS đã xây dựng một quy trình MLOps hoàn chỉnh cho Nền Tảng Kỹ Thuật Số như thế nào Bởi: Gabriel Zylka, Chandana Keswarkar, and Sandro Zangiacomi Ngày: 03 tháng 03 năm 2025\nTừ khóa: Amazon API Gateway, Amazon DataZone, Amazon EventBridge, Amazon SageMaker, Amazon Simple Storage Service (S3), Automotive, AWS CodeArtifact, AWS CodeCommit, AWS Lake Formation, AWS Service Catalog, AWS Step Functions, AWS Well-Architected Framework, Industries\nBối cảnh Vào năm 2019, Volkswagen AG (VW) và Amazon Web Services (AWS) đã hình thành 1 chiến lược hợp tác để phát triển Nền Tảng Kỹ Thuật Số (DPP), chiến lược này được thiết kế để nâng cao hiệu quả sản xuất và vận chuyển của VW lên 30% đồng thời giảm chi phí sản xuất ở mức tương tự. DPP giúp truy cập dữ liệu từ các thiết bị và hệ thống sản xuất của VW, giúp việc xây dựng và triển khai các ứng dụng mới đơn giản và nhanh hơn từ 2-3 lần, đồng thời giảm chi phí thử nghiệm tạo điều kiện chia sẻ các giải pháp giữa các doanh nghiệp VW. Một giải pháp chính được áp dụng là quy trình MLOps hoàn chỉnh cho các bài toán liên quan tới Học máy (ML). Bài viết này trình bày về kiến trúc đã được sử dụng để chuẩn hoá toàn bộ vòng đời của 1 dự án ML, các kinh nghiệm hay nhất, và làm thế nào để triển khai một giải pháp MLOps tương tự trong tổ chức của bạn.\nĐội ngũ VW đã triển khai hơn 100 trường hợp sử dụng tại các công ty và thương hiệu của VW. Phần lớn các trường hợp này là giải pháp dự trên ML trong các lĩnh vực như dự đoán bảo trì, chất lượng, và quá trình tối ưu. Ví dụ, dự đoán bảo trì cho robot súng hàn liên quan đến các cảm biến phát hiện lỗi động cơ hoặc mạch hàn. Những mô hình ML được yêu cầu để dự đoán sớm các lỗi này sớm từ hàng ngàn con robot tại nhiều nhà máy khác nhau. Nhiều nhóm khoa học dữ liệu đã làm việc để tạo ra các giải pháp ML sẵn sàng đưa vào vận hành, tuân thủ các tiêu chuẩn bảo mật của tập đoàn. Tuy nhiên, cách làm phân tán này đã bốc bộ ra nhiều vấn đề:\nCách phát triển k nhất quán: Mỗi nhà máy tự phát triển giải pháp độc lập, đẫn đến kết quả vận hành bị phân mảnh và không có một chiến lược thống nhất. Điều này tạo ra 1 tập hợp các giải pháp thiếu liên kết và rời rạc. Phát triển thiếu hiệu quả: Những nỗ lực dư thừa phát sinh từ các nhóm VW khi phải tạo lại những các thành phần cơ sở hạ tầng tương tự nhau, mỗi thành phần lại yêu cầu đánh giá bảo mật khác nhau làm tăng sự phức tạp. Ảnh hưởng đến thời gian và tài nguyên: Các triển khai ban đầu yêu cầu 2 nhân viên full-time làm việc 2 tháng cho mỗi luồng việc. Việc đào tạo thành viên mới và hoàn thành đánh giá bảo mật cũng lâu hơn vì mỗi nơi có cách triển khai riêng. Vấn đề quản lý quy trình: Với việc không có quy trình tiêu chuẩn, các nhóm VW đã gặp khó khăn trong việc quản lý, truy vết và quản lý phiên bản của mô hình. Việc này làm ảnh hưởng tới tính minh bạch. Thách thức trong việc bảo trì và chất lượng: Các triển khai đa dạng dẫn đến chất lượng không đồng đều, lãng phí tài nguyên, ảnh hưởng tiêu chuẩn kiểm thử, gây khó khăn trong việc áp dụng các phương pháp tốt hơn. Những vấn đề trên đã tạo ra những ảnh hưởng tài chính, làm chậm thời gian ra mắt sản phẩm, tăng chi phí bảo trì và tạo thêm rủi ro trong việc bảo mật. Việc chia sẻ kiến thức trở nên khó khăn, dẫn đến nỗ lực phí sức, lãng phí tài nguyên vào những việc không tạo ra sự khác biệt và tăng thêm gánh nặng cho việc vận hành và bảo trì. Để giải quyết những vấn đề này, VW đã hợp tác với AWS Professional Services để xây dựng 1 giải pháp MLOps an toàn hơn, có khả năng mở rộng cho các doanh nghiệp sử dụng ML để triển khai trên DPP.\nKiến trúc MLOps Kiến trúc được triển khai tại VW đã cho thấy cách MLOps tự động hóa mọi công đoạn, tạo ra một quy trình hiệu quả để quản lý toàn bộ vòng đời của mô hình học máy. Để tìm hiểu sâu hơn, bạn có thể xem bài viết MLOps foundation roadmap for enterprises with Amazon SageMaker. Một chiến lược đa tài khoản giúp quản lý nhiều mô hình. Dưới đây là cách mỗi tài khoản hoạt động:\nTài khoản Data (Dữ liệu): Tài khoản này đóng vai trò như một trung tâm cho việc quản lý dữ liệu, giám sát tất cả quá trình đưa dữ liệu từ các nguồn như hệ thống on-premises hoặc đưa những môi trường khác lên đám mây. Quản trị viên điều khiển và hạn chế truy cập vào các cột dữ liệu cụ thể để đáp ứng yêu cầu của trường hợp sử dụng, đảm bảo tuân thủ thông qua việc ẩn danh khi cần thiết. Để tìm hiểu thêm về cách VW quản lý quyền truy cập và bảo mật dữ liệu sử dụng Amazon DataZone, hãy tham khảo blog post. Tài khoản EXP (Thử nghiệm): Tài khoản này cung cấp một môi trường chuyên dụng cho nhóm khoa học dữ liệu của VW để thực hiện khai phá dữ liệu, thử nghiệm và huấn luyện mô hình. Tài khoản EXP triển khai tất cả tài nguyên trong một VPC được cô lập mà không có quyền truy cập internet. Để có thể sử dụng thư viện của bên thứ ba, một kho lưu trữ AWS CodeArtifact cung cấp quyền truy cập an toàn vào các kho lưu trữ công cộng như PyPI. Các Data Scientist cam kết thay đổi code vào kho lưu trữ AWS CodeCommit (hoặc những nhà cung cấp khác như GitLab, vì quyền truy cập AWS CodeCommit cho người dùng mới đã kết thúc). Khi huấn luyện hoặc suy luận yêu cầu chứa hình ảnh tuỳ chỉnh, các Data Scientists cam kết code được chuyển đến một kho lưu trữ. Sau đó, một CI/CD sẽ quét, kiểm tra và xây dựng hình ảnh trước khi đưa chúng tới một trung tâm Amazon ECR đăng ký ở tài khoản RES. Tài khoản RES (Tài nguyên): Tài khoản này quản lý tất cả cơ sở hạ tầng và việc triển khai mô hình ML. Nó là nơi chứa kho lưu trữ CodeCommit cho các cơ sở hạ tầng như Code (IaC) và quy trình CI/CD của AWS CodePipeline, cho phép có thể triển khai trên tất cả các tài khoản RES, EXP, DEV, INT và PROD. Ngoài ra, tài khoản này cũng nơi nơi chứa các kho lưu trữ Amazon ECR, nơi các nhà khoa học công bố các Docker chứa các hình ảnh tùy chỉnh được sử dụng trong quá trình suy luận của mô hình. Cuối cùng, nó tạo các sản phẩm AWS Service Catalog trong tài khoản EXP để thực hiện các quy trình huấn luấn mô hình và quy trình triển khai mô hình ở tài khoản RES. Tài khoản DEV (Phát triển): Tài khoản này đóng vai trò là môi trường phát triển nơi các nhóm VW ban đầu triển khai các mô hình ML tới các điểm kết thúc của Amazon SageMaker. Tại đây, các mô hình sẽ trải qua quá trình kiểm thử hoàn chỉnh bởi VW cho tất cả những chỉ số của mô hình như hiệu suất và các thông số hạ tầng như thời gian phản hồi và khả năng hoạt động. Trong tài khoản DEV, quản trị viên thường cấp quyền truy cập thủ công cho các nhân viên khoa học dữ liệu và nhóm DevOps để kiểm tra và xử lý sự cố của việc triển khai. Sau khi kiểm tra hoàn tất, bước phê duyệt thủ công trong quy trình CI/CD tại tài khoản RES sẽ đẩu việc triển khai sang giai đoạn INT. Tài khoản INT (Tích hợp): Tài khoản này hoạt động như 1 môi trường staging để triển khai mô hình ML nhằm xác thực việc triển khai và tích hợp cơ sở hạ tầng đã thành công trước khi tiến hành triển khai vào môi trường PROD. Không giống như môi trường DEV, việc triển khai trong tài khoản INT có thể chỉ được truy cập thông qua các quyền chỉ đọc. Sau khi vượt qua tất cả các quy trình kiểm tra, nhóm DevOps sẽ phê duyệt thông qua quy trình CI/CD trong tài khoản RES để triển khai mô hình thành sản phẩm. Tài khoảng PROD (Sản xuất): Tài khoản này lưu trữ phiên bản của mô hình ML trên điểm cuối Amazon SageMaker. Trong môi trường sản xuất, bạn có thể cấu hình SageMaker endpoint with an auto scaling group để tự động mở rộng quy mô điểm cuối lên hoặc xuống dựa trên nhu cầu. MLOps cho Data Scientist Machine learning lifecycle là một quá trình lặp lại, bắt đầu bằng việc xác định một vấn đề doanh nghiệp và quyết định xem ML có phải là giải pháp có thể áp dụng không. Sau khi xác nhận, quá trình sẽ bao gồm việc định hình bài toán ML, theo sau là giai đoạn dữ liệu, nơi mà các Data Engineer thu thập, khai phá, chuẩn bị và phân tích dữ liệu thông qua trực quan hoá dữ liệu. Tiếp theo là Feature Engineering, nơi những kĩ thuật cụ thể như mã hoá, chuẩn hoá và xử lý dữ liệu bị mất. Sau đó là giải đoạn phát triển mô hình, giai đoạn này sẽ bao gồm việc lựa chọn một thuật toàn phù hợp, huấn luyện mô hình, tinh chỉnh các siêu tham số và đánh giá hiệu suất bằng các chỉ số chỉ số đã được định nghĩa trước. Một khi mô hình đạt được tiêu chí hiệu suất mong muốn, nó sẽ được triển khai ra môi trường sản xuất. Theo thời gian, hiệu suất mô hình có thể bị giảm, phải liên tục theo dõi, gỡ lỗi, huấn luyện lại và tái triển khai để duy trì hiệu quả mô hình. Các bước sau đây mô tả luồng làm việc của một Data Scientist cho những giải pháp MLOPS trên các tài khoản khác nhau:\nThu thập dữ liệu và Chuẩn bị dữ liệu: Data Engineer tạo qua các quy trình trích xuất, chuyển đổi và tải (ETL) kết hợp với nhiều nguồn dữ liệu và chuẩn bị các bộ dữ liệu cần thiết cho các bài toàn ML trong tài khoản DATA. Dữ liệu được lập danh mục bằng AWS Glue Data Catalog và chia sẻ với những người dùng và tài khoản khác thông qua AWS Lake Formation để quản lý. Data Scientist được cấp quyền truy cập an toàn vào những bộ dataset cụ thể từ tài khoản DATA. Khai phá dữ liệu và Phát triển mô hình: Mỗi Data Scientist nhận được một hồ sơ người dùng Amazon SageMaker Studio với một vai trò IAM và Nhóm Bảo Mật, để truy cập vào SageMaker Studio và bộ datasets cụ thể của họ trong Amazon S3. Trong không gian làm việc cá nhân của mình, Data Scientist thực hiện các tác vụ như khai phá dữ liệu, huấn luyện mô hình, điều chỉnh siêu tham số, xử lý dữ liệu và đánh giá mô hình, sử dụng Jupyter Notebooks hoặc những dịch vụ SageMaker. Điều này có thể được mở rộng với Amazon SageMaker Feature Store để tái sử dụng. Để biết thêm thông tin, bạn có thể tham khảo Enable feature reuse across accounts and teams using Amazon SageMaker Feature Store. Huấn luyện mô hình và Huấn luyện lại mô hình: Sau giai đoạn thử nghiệm, Data Scientist khởi chạy “Model Building Product” từ AWS Service Catalog. Việc này sẽ khởi tạo một stack CloudFormation để thiết lập một Sagemaker Pipeline để điều phối các tác vụ dữ liệu như xử lý, huấn luyện và đánh giá. Các mô hình ML được huấn luyện và đánh giá thành công sẽ được đăng ký vào Sagemaker Model Registry, nơi lưu trữ lịch sử phiên bản và triển khai siêu dữ liệu, chẳng hạn như các container chứa các hình ảnh và vị trí của các tệp artifact. Đối với việc huấn luyện lại sau này, Data Scientists sẽ kích hoạt Quy trình Huấn luyện, quy trình này sẽ đăng ký một phiên bản mô hình mới vào Model Registry mô hình sau khi thực thi thành công. Khi một phiên bản mô hình mới được đăng ký, một sự kiện tên là Amazon EventBridge được kích hoạt và gửi đến tài khoản RES, khởi động quy trình triển khai. Triển khai Mô hình và Tái triển khai Mô hình: Để tạo một quy trình triển khai mô hình, kỹ sư DevOps khởi chạy sản phẩm “Model Deployment” từ Service Catalog, tham chiếu đến mô hình đã được huấn luyện trong Model Registry. Sản phẩm này sẽ cung cấp một kho lưu trữ CodeCommit cho IaC, một CodePipeline và một quy tắc EventBridge để theo dõi phiên bản mới của mô hình từ tài khoản EXP. Quy trình CI/CD được kích hoạt bởi những thay đổi trong kho lưu trữ CodeCommit và bởi các sự kiện đến từ EventBridge. Nó sẽ truy vấn Model Registry để lấy phiên bản mới nhất và triển khai mô hình cùng các tài nguyên liên quan đến giai đoạn DEV. Sau các bước phê duyệt thủ công, mô hình sẽ tiếp tục được chuyển qua giai đoạn INT và PROD. Lợi ích Quy trình MLOps mới này mang lại nhiều lợi ích quan trọng:\nChuẩn hoá: Bằng cách thay thế nhiều giải pháp tuỳ chỉnh với một quy trình chung thống nhất, VW đã loại bỏ được việc phải làm đi làm lại những công việc giống nhau và thiết lập được các cách làm đồng bộ trong mọi hoạt động ML. Vận hành hiệu quả: Một kiến trúc tài khoản có cấu trúc được chia thành các môi trường khác nhau, phân chia nhiệm vụ rõ ràng và tối ưu toàn bộ vòng đời ML từ lúc thử nghiệm cho đến khi triển khai. Bảo mật và Quản trị: Các rào bảo mật được tích hợp sẵn, bao gồm các vai trò IAM chuyên dụng, các VPCs được cô lập và mã hoá giúp đảm bảo các hoạt động ML đáp ứng tiêu chuẩn bảo mật của doanh nghiệp trong khi vẫn giữ được sự linh hoạt. Khả năng mở rộng: Giải pháp này hiện đang hỗ trợ 8 dự án tại 5 nhà máy, phục vụ cho 16 Data Scientist, với kiến trúc được thiết kế để dễ dàng mở rộng trong tương lai và đáp ứng thêm nhiều dự án mới. Giảm thời gian ra mắt sản phẩm: Một quy trình tự động và chuẩn hoá giờ đây có thể hoàn thành công việc chỉ trong vài ngày, trong khi trước đây cần tới 2 nhân viên làm full-time trong 2 tháng cho 1 dự án. Điều này giúp tăng tốc đáng kể việc triển khai mô hình. Kho lưu trữ mã nguồn mở Kho lưu trữ Github cung cấp một mẫu giải pháp để triển khai hạ tầng MLOps đã được thảo luận trong bài blog này. Giải pháp này sẽ triển khai tổng cộng 13 stack AWS CDK có thể cấu hình được trên khắp 5 tài khoản AWS, cho phép bạn nhanh chóng khởi tạo nền tảng MLOps. Mẫu này rất linh hoạt và có thể được tuỳ chỉnh để đáp ứng các yêu cầu cụ thể của bạn, chẳng hạn như thêm các Service Catalog Product để tinh chỉnh các quy trình huấn luyện và triển khai mô hình. Để thực hiện việc triển khai, bạn sẽ cần quyền truy cập vào 5 tài khoản AWS cho các môi trường sau:\nEXP (Experimentation) RES (Resources) DEV (Development) INT (Integration) PROD (Production) Để biết các yêu cầu cần có trước và hướng dẫn triển khai, hãy tham khảo tệp README.md trong kho lưu trữ.\nCác Extensions khả thi Các Extensions sau có thể nâng cao giải pháp MLOps để đáp ứng nhu cầu cho từng trường hợp cụ thể:\nXử lý hàng loạt (Batch Processing) Mặc dù suy luận trực tuyến cung cấp các dự đoán theo thời gian thực với độ trễ thấp, suy luận hàng loạt là lựa chọn lý tưởng cho các tình huống mà dữ liệu được đưa đến hàng loạt theo các khoảng thời gian đều đặn và không yêu cầu kết quả ngay lập tức. Suy luận hàng loạt đặc biệt phù hợp cho các nhu cầu suy luận định kỳ. Bằng cách sử dụng Amazon SageMaker, bạn có thể thực hiện suy luận hàng loạt bằng cách chạy một batch transform job trên một Mô hình SageMaker hoặc điều phối một quy trình suy luận hàng loạt với AWS Step Functions.. Kết quả được tự động lưu trữ trong Amazon S3.\nAPI Gateway Để phục vụ các mô hình thông qua các điểm cuối API tùy chỉnh, hãy sử dụng Amazon API Gateway, một dịch vụ được quản lý hoàn toàn để tạo, xuất bản, duy trì, giám sát và bảo mật các API ở mọi quy mô. Các yêu cầu được định tuyến qua API Gateway đến AWS Lambda, dịch vụ này sẽ gọi điểm cuối của SageMaker và trả về các phản hồi cho API Gateway để kiểm thử và phục vụ các dự đoán.\nGiám sát mô hình Amazon SageMaker Model Monitor giúp cho phép theo dõi liên tục hiệu suất của mô hình sau khi triển khai trong môi trường sản xuất. Công cụ này thu thập các mẫu dữ liệu đầu vào và các dự đoán của mô hình theo các khoảng thời gian được lên lịch, giám sát các chỉ số như chất lượng dữ liệu, chất lượng mô hình, độ lệch và khả năng giải thích. Nếu Model Monitor phát hiện bất kỳ sự sai lệch hoặc suy giảm nào, nó sẽ tạo ra các cảnh báo, cho phép bạn thực hiện các hành động khắc phục như thu thập dữ liệu huấn luyện mới, huấn luyện lại mô hình hoặc kiểm tra các hệ thống ở đầu nguồn . Tìm hiểu thêm về Monitoring in-production ML models at large scale using Amazon SageMaker Model Monitor.\nHàng rào an ninh Giải pháp MLOps của VW tuân theo các phương pháp bảo mật tốt nhất của AWS từ AWS Well Architected Framework Security pillar và từ sách trắng của AWS có tên Build a Secure Enterprise Machine Learning Platform on AWS. Ngoài các tính năng bảo mật được triển khai trong mỗi tài khoản VW AWS, dưới đây là một số phương pháp tốt nhất khác đã được tuân thủ:\nBảo vệ cơ sở hạ tầng: Tất cả tài nguyên đều được phân tách trong các mạng con VPC tự quản lý. Tất cả các dịch vụ AWS đều được truy cập thông qua các VPC Service Endpoints. Bảo vệ dữ liệu: Mọi dữ liệu lưu trữ đều được mã hóa bằng khóa mã hóa do khách hàng quản lý. Môi trường SageMaker Studio được mã hóa khi lưu trữ. Xác định và quản lý quyền truy cập: Các vai trò IAM chuyên dụng được gán cho người dùng SageMaker Studio, các đường ống, công việc đào tạo và điểm cuối mô hình. Các vai trò IAM được tạo bằng cách sử dụng các persona của Amazon SageMaker Role Manager để thực thi quyền truy cập có đặc quyền thấp nhất. Các chính sách từ chối IAM rõ ràng để hạn chế việc đào tạo mô hình hoặc triển khai mô hình bên ngoài VPC hoặc không cần mã hóa. Kiểm tra: Kiểm tra bảo mật thường xuyên được thực hiện để xác định và giảm thiểu các lỗ hổng. AWS Config được sử dụng để theo dõi các thay đổi cấu hình và đảm bảo tuân thủ các chính sách bảo mật. AWS Security Hub tổng hợp các phát hiện bảo mật từ nhiều dịch vụ AWS để quản lý và khắc phục tập trung. Tìm hiểu thêm về VW secures landing zone with automated remediation of security findings. Tổng kết Sự hợp tác giữa VW và AWS đã chuyển đổi thành công một bối cảnh MLOps phân mảnh thành một quy trình sản xuất ML (Học máy) được tiêu chuẩn hóa, hiệu quả và an toàn hơn. Bằng cách triển khai một giải pháp MLOps toàn diện được xây dựng trên Amazon SageMaker, VW đã giải quyết các thách thức của việc phát triển phi tập trung, để thiết lập một vòng đời ML hợp lý, có khả năng mở rộng và an toàn hơn thông qua kiến trúc MLOps đa tài khoản. Việc triển khai này có thể đóng vai trò như một bản thiết kế cho các doanh nghiệp khác đang tìm cách tiêu chuẩn hóa các hoạt động MLOps của họ ở quy mô lớn. Nếu bạn quan tâm đến việc khám phá các giải pháp tương tự hoặc cần hướng dẫn xây dựng giải pháp MLOps của riêng mình, hãy truy cập AWS for automotive page hoặc contact với nhóm AWS của bạn ngay hôm nay.\nTác Giả Gabriel Zylka: Là Kỹ sư học máy tại AWS Professional Services. Anh làm việc chặt chẽ với khách hàng để đẩy nhanh hành trình chuyển đổi số sang công nghệ đám mây. Chuyên về lĩnh vực MLOps, anh tập trung vào việc sản xuất khối lượng công việc ML bằng cách tự động hóa vòng đời ML từ đầu đến cuối và giúp đạt được kết quả kinh doanh mong muốn. Chandana Keswarkar: Là Kiến trúc sư Giải pháp cao cấp AWS, chuyên hướng dẫn khách hàng trong lĩnh vực ô tô trong hành trình chuyển đổi số bằng công nghệ đám mây. Cô giúp các tổ chức phát triển và tinh chỉnh kiến trúc nền tảng và sản phẩm, đồng thời đưa ra các quyết định thiết kế sáng suốt. Trong thời gian rảnh rỗi, cô thích đi du lịch, đọc sách và tập yoga. Sandro Zangiacomi: Là chuyên gia AI dịch vụ chuyên nghiệp của AWS tại Paris. Trong vai trò hiện tại, anh hỗ trợ khách hàng điều phối quy trình làm việc máy học và xây dựng nền tảng học máy cho nhiều trường hợp sử dụng khác nhau, bao gồm cả việc triển khai GenAI. Trong thời gian rảnh rỗi, anh thích dành những khoảnh khắc chất lượng bên bạn bè tại Paris và học hỏi về hầu hết mọi thứ, từ phát triển bản thân đến thời trang. "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"Triển khai thử nghiệm khôi phục để xác thực phục hồi bằng AWS Backup Bởi Gabe Contreras và Sabith Venkitachalapathy | 28 tháng 3 năm 2025 Phân loại: Advanced (300), AWS Backup, Storage, Technical\nCác ứng dụng quan trọng là nền tảng cho mọi thứ, từ thương mại điện tử đến chăm sóc sức khỏe, khiến cho một chiến lược sao lưu vững chắc không chỉ là một phương pháp hay nhất mà còn là một nhu cầu thiết yếu. Các mối đe dọa như ransomware (phần mềm tống tiền) ngày càng trở nên tinh vi hơn, và đối với người dùng AWS, chỉ có các bản sao lưu thôi là chưa đủ. Các tổ chức cần tin tưởng rằng những biện pháp bảo vệ này sẽ hoạt động hiệu quả khi thảm họa xảy ra.\nViệc kiểm thử thủ công, mặc dù cần thiết, nhưng lại làm tiêu tốn tài nguyên Công nghệ thông tin. Thông qua việc kiểm thử khôi phục tự động theo lịch trình đã định, các tổ chức đạt được nhiều hơn là chỉ hiệu quả: họ thiết lập một hệ thống giúp xác minh tính toàn vẹn của bản sao lưu, hợp lý hóa việc báo cáo tuân thủ, và giải phóng nguồn nhân lực quý giá—tất cả những điều này đồng thời xây dựng sự chắc chắn rằng chiến lược bảo vệ của họ sẽ mang lại hiệu quả khi cần thiết.\nTrong bài viết trước của chúng tôi, Validating recovery readiness with AWS Backup restore testing, chúng tôi đã tìm hiểu lý do tại sao việc kiểm thử và khôi phục của AWS Backup lại quan trọng để đáp ứng các chính sách phục hồi sau sự cố (DR) nội bộ và các yêu cầu pháp lý. Trong bối cảnh kỹ thuật số được định hình bởi các quy định như European Union’s Digital Operational Resilience Act (DORA) của Liên minh Châu Âu và New York Department of Financial Services (NYDFS), khả năng phục hồi không chỉ là mục tiêu mà còn là một yêu cầu bắt buộc. Việc kiểm thử khôi phục của AWS Backup có thể cung cấp bằng chứng được yêu cầu bởi các quy định này; trong khi đó, các tính năng kiểm thử và kiểm toán mang lại nhiều khả năng để giúp các tổ chức xác thực và báo cáo về những nỗ lực tăng cường khả năng phục hồi của mình.\nTrong bài viết này, bạn sẽ tìm hiểu cách để thiết lập cấu hình AWS Backup restore testing và một số phương pháp hay nhất cần cân nhắc khi tạo kế hoạch của riêng mình. Bạn cũng sẽ nhận được một ví dụ để xem cách kiểm tra khôi phục đầu cuối hoạt động trong thực tế.\nCơ chế hoạt động của kiểm thử khôi phục AWS Backup AWS Backup restore testing cho phép người dùng kiểm thử việc khôi phục dữ liệu theo một lịch trình định trước và xác thực dữ liệu đã được khôi phục. Khả năng thiết lập lịch trình và tạo ra các quy trình tự động để kiểm tra việc khôi phục dữ liệu giúp giảm bớt công sức thủ công và giúp đáp ứng các yêu cầu về tuân thủ.\nNếu không có kiểm thử khôi phục tự động, nhân sự có thể sẽ phải chọn các hệ thống và các điểm khôi phục, hoàn thành việc khôi phục thủ công, và yêu cầu các đội ngũ ứng dụng xác thực dữ liệu đã được khôi phục. Việc này tiêu tốn thời gian và tài nguyên của nhiều đội ngũ, mà lẽ ra có thể được sử dụng hiệu quả hơn để cải thiện các ứng dụng. Khi tự động hóa quy trình này, chúng ta có thể tạo ra các quy trình xác thực dữ liệu để xác thực các lần khôi phục một cách thường xuyên.\nMột AWS Backup restore testing plan được xây dựng qua hai giai đoạn:\nĐầu tiên, bạn tạo kế hoạch kiểm thử khôi phục. Thứ hai, bạn tạo các lựa chọn tài nguyên được bảo vệ sẽ được khôi phục bởi kế hoạch kiểm thử đó. Khi AWS Backup hoàn tất việc khôi phục, bạn có thể xây dựng quy trình xác thực cho việc kiểm thử khôi phục bằng các hàm AWS Lambda được kích hoạt bởi Amazon EventBridge. Các hàm Lambda có thể thực hiện nhiều hoạt động xác thực khác nhau—bao gồm kiểm tra khả năng kết nối, truy xuất các đối tượng từ Amazon S3, hoặc lấy trạng thái của khóa mã hóa để xác thực dữ liệu thực tế—sau đó báo cáo lại cho AWS Backup về việc liệu quá trình xác thực đó thành công hay thất bại. Sau khi kiểm thử khôi phục hoàn tất, bạn có thể sử dụng các báo cáo của AWS Backup Audit Manager để chứng minh sự tuân thủ khi cần thiết.\nXây dựng kế hoạch khôi phục thử nghiệm Bước đầu tiên của việc triển khai kiểm thử khôi phục là xây dựng kế hoạch kiểm thử khôi phục. Vì có nhiều yếu tố cần cân nhắc về tần suất kiểm thử và những gì cần kiểm thử, chúng tôi sẽ tập trung vào các phương pháp tốt nhất và các khuyến nghị. Một kế hoạch kiểm thử khôi phục bao gồm ba phần:\nTần suất kiểm tra (Test frequency) Quy định thời gian bắt đầu (Start within time) Các tiêu chí để lựa chọn điểm phục hồi (Recovery point selection criteria) Với Tần suất kiểm thử, bạn nên kiểm thử các tài nguyên quan trọng hàng ngày hoặc hàng tuần. Bạn nên kiểm thử các tài nguyên trong khoảng thời gian lưu giữ của chúng, nghĩa là nếu chúng ta giữ các điểm khôi phục trong 14 ngày, bạn nên cho việc kiểm thử chạy thường xuyên hơn thế.\nQuy định thời gian bắt đầu phụ thuộc vào số lượng điểm khôi phục bạn sẽ kiểm thử và mỗi lần khôi phục mất bao lâu để hoàn thành. Mỗi dịch vụ có maximum concurrent restores (giới hạn phục hồi đồng thời tối đa) được phép, và bạn cần đảm bảo các kế hoạch của mình được giãn cách ra để không vượt quá giới hạn đó. Việc Lựa chọn điểm khôi phục có thể bao gồm tất cả hoặc các kho lưu trữ cụ thể, khung thời gian cho các điểm khôi phục đủ điều kiện, và liệu có bao gồm các loại tài nguyên khôi phục tại một thời điểm cụ thể (PITR) hay không. Bạn có thể có một kho lưu trữ cho mỗi tài khoản, hoặc nhiều kho lưu trữ dựa trên các loại ứng dụng hoặc các cấp độ (tiers). Nếu bạn đang sao chép dữ liệu đến một tài khoản sao lưu trung tâm, một thiết kế tối ưu sẽ là tạo ra một logically air-gapped (LAG) vault cho mỗi tài khoản nguồn. Sau khi tạo kế hoạch kiểm thử khôi phục, bạn chuyển sang giai đoạn 2: tạo các lựa chọn tài nguyên được bảo vệ. Với mỗi lựa chọn tài nguyên, bạn phải chọn một loại tài nguyên duy nhất, chẳng hạn như Amazon S3 hoặc Amazon Relational Database Service (Amazon RDS). Sau khi chọn một loại tài nguyên, kiểm thử khôi phục cho phép bạn tùy chỉnh thêm những tài nguyên cụ thể nào sẽ được chọn. Mỗi kế hoạch kiểm thử khôi phục cho phép tối đa 30 lựa chọn tài nguyên được bảo vệ. Khi tạo phần gán tài nguyên, bạn có thể chọn vai trò IAM mặc định của AWS Backup. Nếu vai trò mặc định không tồn tại, vai trò đó sẽ được tạo ra với các quyền phù hợp. Bạn có thể lọc các tài nguyên theo lựa chọn riêng lẻ hoặc theo thẻ, điều này cho phép bạn chọn các tài nguyên cụ thể để kiểm thử dựa trên yêu cầu của mình. Trong Hình 4, chúng tôi chọn S3 làm loại tài nguyên, sau đó chọn lọc theo thẻ (tag) để chọn các bucket cụ thể.\nMỗi dịch vụ có một bộ siêu dữ liệu khôi phục khả thi riêng, cung cấp các giá trị mặc định để thực hiện kiểm thử khôi phục thành công, trong đó AWS Backup sẽ tự suy ra một bộ siêu dữ liệu khôi phục ở mức tối thiểu. Ngoài ra còn có siêu dữ liệu có thể ghi đè mà bạn có thể thay đổi để ghi đè lên các giá trị mặc định. Bạn có thể đọc thêm về siêu dữ liệu được suy ra và siêu dữ liệu có thể ghi đè trong documentation của AWS Backup. Sau khi xác định kế hoạch tổng thể và lựa chọn nguồn lực, chúng ta có một kế hoạch hoạt động đầy đủ như trong Hình 5. Triển khai xác thực khôi phục Việc cấu hình một kế hoạch kiểm thử khôi phục mới chỉ là một nửa công việc; bạn còn phải xác minh rằng dữ liệu đã được khôi phục của mình có thể sử dụng được. AWS Backup gửi các sự kiện của Amazon EventBridge cho những thay đổi về trạng thái của công việc khôi phục. Chúng ta có thể sử dụng các sự kiện này để kích hoạt một hàm AWS Lambda khi một công việc kiểm thử khôi phục chuyển sang trạng thái hoàn thành, điều này cho phép các đội ngũ ứng dụng tạo ra mã code để kiểm thử dữ liệu của họ. Mã kiểm thử phụ thuộc vào dịch vụ bạn đang bảo vệ, nhưng có thể bao gồm việc truy xuất các đối tượng từ một bucket S3 hoặc truy vấn Amazon DyanamoDB. Sau khi hàm Lambda của bạn chạy xong, nó có thể báo cáo lại cho AWS Backup về việc thành công hay thất bại. Hình 6 minh họa quy trình xác thực khôi phục mẫu này. Nếu bạn có nhiều kế hoạch kiểm tra khôi phục, bạn có thể tùy chỉnh quy tắc EventBridge để gửi các sự kiện nhất định đến các chức năng tương ứng (như minh họa trong Hình 7) bằng cách bao gồm Amazon Resource Name (ARN) của kế hoạch kiểm tra khôi phục. Việc sử dụng ARN của kế hoạch kiểm tra khôi phục cũng cho phép bạn lọc bỏ các lần khôi phục thủ công. Sau khi tạo mẫu sự kiện , bạn chọn một mục tiêu để gửi sự kiện đến. Nếu bạn có nhiều loại tài nguyên yêu cầu các tiêu chí kiểm thử riêng biệt, một hàm Lambda điều phối có thể giúp gửi các sự kiện cho các loại tài nguyên khác nhau đến đúng quy trình xác thực. Hàm Lambda điều phối này sẽ kiểm tra loại tài nguyên và định tuyến sự kiện đến hàm Lambda xác thực dữ liệu tương ứng. Nếu bạn có nhiều loại tài nguyên được bảo vệ, bạn sẽ chọn hàm Lambda điều phối này làm mục tiêu cho các sự kiện EventBridge, như được thấy trong Hình 8. Sau đây là mẫu mã điều phối Lambda khôi phục:\nimport json import boto3 import logging logger = logging.getLogger() logger.setLevel(logging.INFO) lambda_client = boto3.client(\u0026#39;lambda\u0026#39;) def handler(event, context): logger.info(\u0026#34;Handling event: %s\u0026#34;, json.dumps(event)) resource_type = event.get(\u0026#39;detail\u0026#39;, {}).get(\u0026#39;resourceType\u0026#39;, \u0026#39;\u0026#39;) function_name = None try: if resource_type == \u0026#34;RDS\u0026#34;: function_name = \u0026#34;RDSRestoreValidation\u0026#34; logger.info(\u0026#34;Resource is an RDS instance. Invoking Lambda function: %s\u0026#34;, function_name) elif resource_type == \u0026#34;S3\u0026#34;: function_name = \u0026#34;S3RestoreValidation\u0026#34; logger.info(\u0026#34;Resource is an S3 bucket. Invoking Lambda function: %s\u0026#34;, function_name) else: raise ValueError(f\u0026#34;Unsupported resource type: {resource_type}\u0026#34;) # Invoke the appropriate Lambda function response = lambda_client.invoke( FunctionName=function_name, Payload=json.dumps(event), InvocationType=\u0026#34;RequestResponse\u0026#34; ) logger.info(\u0026#34;Lambda invoke response: %s\u0026#34;, response) except Exception as e: logger.error(\u0026#34;Error during Lambda invocation: %s\u0026#34;, str(e)) raise e logger.info(\u0026#34;Finished processing event for resource type: %s\u0026#34;, resource_type) Trong đoạn mã của hàm Lambda điều phối khôi phục, bạn có thể thấy rằng nếu loại tài nguyên khớp với S3, nó sẽ chuyển tiếp toàn bộ sự kiện đến một hàm Lambda khác có tên là S3RestoreValidation. Hàm S3RestoreValidation này sau đó sẽ tiến hành xác thực việc khôi phục trên một tài nguyên S3 và báo cáo lại cho AWS Backup về việc xác thực đó thành công hay thất bại.\nimport json import boto3 import logging logger = logging.getLogger() logger.setLevel(logging.INFO) s3_client = boto3.client(\u0026#39;s3\u0026#39;) backup_client = boto3.client(\u0026#39;backup\u0026#39;) def handler(event, context): logger.info(\u0026#34;Handling event: %s\u0026#34;, json.dumps(event)) restore_job_id = event.get(\u0026#39;detail\u0026#39;, {}).get(\u0026#39;restoreJobId\u0026#39;, \u0026#39;\u0026#39;) resource_type = event.get(\u0026#39;detail\u0026#39;, {}).get(\u0026#39;resourceType\u0026#39;, \u0026#39;\u0026#39;) created_resource_arn = event.get(\u0026#39;detail\u0026#39;, {}).get(\u0026#39;createdResourceArn\u0026#39;, \u0026#39;\u0026#39;) validation_status = \u0026#34;SUCCESSFUL\u0026#34; validation_status_message = \u0026#34;Restore validation completed successfully\u0026#34; try: if resource_type == \u0026#34;S3\u0026#34;: bucket_name = get_bucket_name_from_arn(created_resource_arn) # List objects in the bucket response = s3_client.list_objects_v2(Bucket=bucket_name) # Check if the bucket contains more than 1 object object_count = response.get(\u0026#39;KeyCount\u0026#39;, 0) if object_count \u0026gt; 1: logger.info(f\u0026#34;Bucket {bucket_name} contains more than 1 object. Validation successful.\u0026#34;) else: logger.info(f\u0026#34;Bucket {bucket_name} contains 1 or fewer objects. Validation failed.\u0026#34;) validation_status = \u0026#34;FAILED\u0026#34; validation_status_message = f\u0026#34;Bucket {bucket_name} contains only {object_count} object(s).\u0026#34; else: validation_status = \u0026#34;FAILED\u0026#34; validation_status_message = f\u0026#34;Unsupported resource type: {resource_type}\u0026#34; # Report validation result to AWS Backup backup_client.put_restore_validation_result( RestoreJobId=restore_job_id, ValidationStatus=validation_status, ValidationStatusMessage=validation_status_message ) logger.info(\u0026#34;Restore validation result sent successfully\u0026#34;) except Exception as e: logger.error(\u0026#34;Error during restore validation: %s\u0026#34;, str(e)) validation_status = \u0026#34;FAILED\u0026#34; validation_status_message = f\u0026#34;Restore validation encountered an error: {str(e)}\u0026#34; # Report failure result to AWS Backup backup_client.put_restore_validation_result( RestoreJobId=restore_job_id, ValidationStatus=validation_status, ValidationStatusMessage=validation_status_message ) logger.info(\u0026#34;Finished processing restore validation for job ID: %s\u0026#34;, restore_job_id) def get_bucket_name_from_arn(arn): arn_parts = arn.split(\u0026#34;:\u0026#34;) resource_parts = arn_parts[-1].split(\u0026#34;/\u0026#34;) return resource_parts[-1] Đoạn mã S3RestoreValidation xác thực khôi phục S3 bằng cách xác minh rằng bucket đó có nhiều hơn một đối tượng bên trong. Sau khi kiểm tra, nó sẽ báo cáo lại cho AWS Backup về việc liệu lần khôi phục đó đã hoàn thành thành công hay chưa. Một lần khôi phục và xác thực hoàn toàn thành công sẽ cho ra một bản tóm tắt như Hình 9. Trạng thái của công việc sẽ là Completed (Hoàn thành), và trạng thái xác thực sẽ là Successful (Thành công). Khi thiết lập trạng thái xác thực trong mã Lambda của bạn, bạn có thể tùy chọn thêm một thông báo xác thực, thông báo này sẽ xuất hiện trong giao diện điều khiển và các API của AWS Backup. Bạn có thể đọc thêm về xác thực khôi phục và các ví dụ trong tài liệu hướng dẫn. AWS Backup tự động bắt đầu quá trình xóa tài nguyên đã được khôi phục khi việc xác thực được gửi đi hoặc khi khoảng thời gian dọn dẹp hết hạn. Thời gian xóa có thể khác nhau tùy thuộc vào loại tài nguyên. Hầu hết các tài nguyên được xóa nhanh chóng, nhưng một số có thể mất nhiều thời gian hơn. Ví dụ, việc xóa một bucket S3 là một quy trình gồm hai bước: đầu tiên là thêm các quy tắc vòng đời để xóa các đối tượng, và sau đó là xóa bucket khi nó đã trống. Các quy tắc vòng đời này có thể mất vài ngày để được thực thi.\nNhững cân nhắc khi kiểm tra khôi phục AWS Backup Bây giờ bạn đã hiểu các phương pháp hay nhất để tạo kế hoạch kiểm tra và xác thực khôi phục, vẫn còn một số chi tiết triển khai khác mà bạn nên cân nhắc.\nTối ưu chi phí Tối ưu hóa chi phí đóng vai trò quan trọng trong suốt vòng đời sao lưu, bao gồm cả thử nghiệm khôi phục. Sau đây là cách quản lý chi phí hiệu quả:\nChọn tài nguyên một cách hợp lý: Sử dụng thẻ hoặc lựa chọn để chỉ kiểm tra các tài nguyên quan trọng, tránh các tài nguyên không phải tài nguyên sản xuất trừ khi việc tuân thủ yêu cầu. Lên lịch kiểm tra theo mức độ quan trọng: Lên lịch kiểm tra theo mức độ quan trọng (hàng ngày hoặc hàng tuần đối với các tài nguyên quan trọng, hàng quý hoặc nửa năm đối với các tài nguyên khác) phù hợp với chính sách và thời gian lưu giữ (ví dụ: kiểm tra trong vòng 14 ngày nếu thời gian lưu giữ là 14 ngày). Tối ưu hóa thời gian lưu giữ: Giảm thiểu thời gian khôi phục dữ liệu để giảm chi phí. Thiết lập thời gian xóa dựa trên các thử nghiệm tự động. Giá tham khảo cho thử nghiệm khôi phục có thể được tìm thấy trên trang giá AWS Backup pricing page.\nKiểm toán và báo cáo sao lưu AWS AWS Backup Audit Manager giúp bạn đảm bảo các chính sách và tài nguyên sao lưu của mình tuân thủ các tiêu chuẩn nội bộ hoặc quy định. Công cụ này theo dõi liệu các tài nguyên có được sao lưu hay không, tần suất sao lưu, liệu các kho lưu trữ có được cách ly về mặt logic hay không, và liệu thời gian khôi phục có đáp ứng mục tiêu hay không. Các khuôn khổ kiểm toán của AWS Backup Audit Manager cho phép thực hiện điều này bằng cách cung cấp các cơ chế kiểm soát có sẵn hoặc các tùy chọn tùy chỉnh để đảm bảo tài nguyên tuân thủ chính sách.\nCác báo cáo kiểm toán cung cấp bằng chứng về sự tuân thủ để có thể chia sẻ. Có hai loại báo cáo:\nBáo cáo công việc: Hiển thị các công việc đã hoàn thành và đang hoạt động trong 24 giờ qua (ví dụ: báo cáo công việc khôi phục cho các lần khôi phục gần đây). Báo cáo tuân thủ: Giám sát trạng thái tài nguyên hoặc các cơ chế kiểm soát của khuôn khổ. Các tài khoản quản lý có được khả năng hiển thị trên nhiều tài khoản để tạo các báo cáo trên toàn tổ chức. Hãy xem tài liệu của AWS Backup documentation để biết các bước tạo báo cáo và thông tin chi tiết về cách sử dụng các khuôn khổ.\nKhôi phục kế hoạch thử nghiệm Khi tạo các kế hoạch kiểm thử khôi phục, hãy đảm bảo rằng các kế hoạch của bạn đáp ứng các yêu cầu kiểm thử và hoàn thành đúng hạn. Mỗi loại tài nguyên có một giới hạn về số lượng công việc khôi phục đồng thời từ các kế hoạch kiểm thử (không phải các lần khôi phục theo yêu cầu).\nKhung thời gian \u0026ldquo;Start within\u0026rdquo; từ giai đoạn 1 là yếu tố then chốt. Cấu hình \u0026ldquo;Start within\u0026rdquo; có nghĩa là tất cả các lựa chọn tài nguyên cho một kế hoạch kiểm thử khôi phục phải bắt đầu trong khung thời gian này, và bạn cần cẩn thận để không vượt quá giới hạn đồng thời.\nVí dụ: Amazon S3 cho phép 30 lần khôi phục đồng thời, vì vậy việc chọn 90 bucket với khung thời gian một giờ có nguy cơ gây ra sự chậm trễ.\nĐể lên kế hoạch hiệu quả, hãy sử dụng một khung thời gian \u0026ldquo;start within\u0026rdquo; dài hơn hoặc tạo nhiều kế hoạch với các thời điểm bắt đầu so le nhau—đặc biệt là khi các bài kiểm thử thường xuyên (hàng ngày/hàng tuần) và định kỳ (hàng tháng/hàng quý) chạy cùng lúc. Hãy kiểm tra các giới hạn có thể điều chỉnh trong documentation và yêu cầu tăng giới hạn nếu cần.\nTrực quan hoá hoàn chỉnh quá trình thử nghiệm Để xem cách thức hoạt động của kiểm thử khôi phục toàn diện và cách triển khai và tích hợp các kế hoạch kiểm thử, chúng tôi đã đưa vào một kế hoạch kiểm thử khôi phục mẫu. Kế hoạch mẫu này giúp bạn hình dung từng bước của quy trình và xem cách khôi phục và xác thực tương tác với nhau.\nĐây là một AWS CloudFormation được cấu hình sẵn, chạy tự động theo lịch trình hàng ngày.\nĐiều kiện tiên quyết Các điều kiện tiên quyết sau đây là cần thiết để hoàn thành giải pháp này:\nAWS Backup được cấu hình trong tài khoản của bạn. Điểm khôi phục của Amazon S3 và/hoặc Amazon RDS. Khởi chạy AWS CloudFormation stack Mẫu AWS CloudFormation này triển khai mọi thứ cần thiết để tự động kiểm tra khôi phục cả Amazon S3 và Amazon RDS.\nhttps://awsstorageblogresources.s3.us-west-2.amazonaws.com/blog1418/CFAWSBackupRestoreTestingV15.yaml\nChạy kế hoạch thử nghiệm khôi phục Sau khi triển khai, không cần can thiệp thủ công để chạy kế hoạch. Kế hoạch kiểm tra khôi phục chạy một lần mỗi ngày trên tất cả các tài nguyên được kế hoạch đó chọn. Như đã lưu ý trong Hình 6, AWS Backup hoàn tất quá trình khôi phục, sau đó chạy các hàm Lambda để xác thực các lần khôi phục.\nKhi quá trình xác thực hoàn tất thành công, quá trình xác thực sẽ hiển thị như trong Hình 10. Dọn dẹp Tất cả các tài nguyên đã được khôi phục từ kế hoạch kiểm thử khôi phục sẽ tự động bị xóa sau bốn giờ. Nếu bạn đang sử dụng kiểm thử khôi phục cho các tài nguyên Amazon S3, thì việc xóa các bucket S3 chứa dữ liệu sẽ mất nhiều thời gian hơn. Điều này là do các quy tắc vòng đời (lifecycle rules) mất vài ngày để thực thi. Để tránh phát sinh thêm chi phí, hãy xóa ngăn xếp (stack) CloudFormation, thao tác này sẽ xóa các kế hoạch kiểm thử khôi phục và dừng các lần kiểm thử sau này. Để biết hướng dẫn, hãy tham khảo mục Deleting a stack on the CloudFormation console.\nTổng kết Kiểm thử khôi phục của AWS Backup là một tính năng linh hoạt và có thể mở rộng, cho phép bạn điều chỉnh một giải pháp phù hợp với nhu cầu của tổ chức mình. Bạn có thể bắt đầu bằng cách tìm hiểu các chính sách của tổ chức, sau đó khám phá các khả năng kiểm thử khôi phục của AWS Backup trong AWS Management Console và học cách tích hợp kiểm thử tự động vào các chiến lược phục hồi sau thảm họa (DR) và khả năng phục hồi không gian mạng của mình. Để triển khai kiểm thử khôi phục của AWS Backup trong môi trường của bạn, hãy truy cập AWS Backup documentation. Bạn cũng có thể làm việc với các Kiến trúc sư Giải pháp của AWS để thiết kế một chiến lược xác thực sao lưu toàn diện được điều chỉnh cho phù hợp với nhu cầu của tổ chức bạn.\nThông điệp rất rõ ràng: việc xác thực sao lưu tự động không còn là một lựa chọn tùy chọn, đó là một yêu cầu cơ bản để đảm bảo hoạt động kinh doanh liên tục trong thời hiện đại. Việc kiểm thử thường xuyên giúp đáp ứng các chính sách nội bộ, các yêu cầu pháp lý, và các yêu cầu về khả năng phục hồi không gian mạng, trong khi đó, kiểm thử khôi phục của AWS Backup cung cấp một giải pháp hiệu quả, có khả năng mở rộng để đảm bảo sự sẵn sàng phục hồi.\nThông tin tác giả Gabe Contreras Gabe Contreras là Kiến trúc sư Giải pháp Lưu trữ Cao cấp cho bộ phận Tài khoản Chiến lược. Anh luôn mong muốn được trao đổi sâu với khách hàng để tìm ra giải pháp tốt nhất cho nhu cầu của họ. Anh luôn thích tìm hiểu cách thức vận hành của mọi thứ và giải quyết các vấn đề phức tạp.\nSabith Venkitachalapathy Sabith Venkitachalapathy là chuyên gia thiết kế các giải pháp phục hồi AWS, đảm bảo khả năng phục hồi sau thảm họa và tính khả dụng cao cho các khối lượng công việc quan trọng. Tập trung vào Dịch vụ Tài chính (FSI) và Chăm sóc Sức khỏe và Khoa học Đời sống (HCLS), Sabith tận dụng AWS để giải quyết các thách thức trong ngành và thúc đẩy đổi mới. Anh chia sẻ những hiểu biết thực tế để giúp các tổ chức xây dựng kiến trúc đám mây an toàn và linh hoạt.\n"},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Cải thiện hiệu suất PostgreSQL bằng cách sử dụng tiện ích mở rộng pgstattuple bởi Vivek Singh, Kiran Singh, and Sagar Patel | Ngày 02 tháng 03 năm 2025 | tại Advanced (300), Amazon Aurora, Amazon RDS, PostgreSQL compatible, RDS for PostgreSQL, Technical How-to\nKhi các doanh nghiệp tiếp tục tạo ra và lưu trữ lượng dữ liệu khổng lồ, nhu cầu về các hệ thống quản lý cơ sở dữ liệu hiệu quả và đáng tin cậy ngày càng trở nên quan trọng. PostgreSQL, một hệ quản trị cơ sở dữ liệu quan hệ (RDBMS) mã nguồn mở, đã tự khẳng định mình là một giải pháp mạnh mẽ để xử lý các yêu cầu dữ liệu phức tạp. Một trong những thế mạnh chính của PostgreSQL nằm ở khả năng mở rộng của nó (extensibility). Thông qua một hệ sinh thái phong phú gồm các phần mở rộng và plugin, các nhà phát triển có thể nâng cao chức năng của cơ sở dữ liệu để đáp ứng các yêu cầu cụ thể. Các phần mở rộng này bao gồm từ hỗ trợ dữ liệu không gian và khả năng tìm kiếm toàn văn bản đến các kiểu dữ liệu nâng cao và các công cụ tối ưu hóa hiệu suất. Mặc dù PostgreSQL cung cấp một loạt các tính năng và khả năng, một phần mở rộng thường bị bỏ qua là pgstattuple—một công cụ có thể cung cấp giá trị đáng kể để có được thông tin chi tiết về hoạt động bên trong của cơ sở dữ liệu PostgreSQL.\nTrong bài đăng này, chúng tôi khám phá sâu về pgstattuple—nó cung cấp những thông tin chi tiết nào, cách sử dụng nó để chẩn đoán các sự cố trong Amazon Aurora PostgreSQL-Compatible Edition và Amazon Relational Database Service (Amazon RDS) for PostgreSQL, và các phương pháp hay nhất để khai thác khả năng của nó.\nTổng quan về pgstattuple Phần mở rộng pgstattuple cung cấp một tập hợp các hàm để truy vấn số liệu thống kê chi tiết ở cấp độ tuple (bản ghi) trong các bảng và chỉ mục của PostgreSQL. Điều này cho phép nhìn sâu vào lớp lưu trữ vật lý mà các chế độ xem thống kê tiêu chuẩn của PostgreSQL không thể cung cấp.\nMột số số liệu cấp bảng và chỉ mục mà pgstattuple cung cấp bao gồm:\ntuple_count – Số lượng tuple đang hoạt động (live tuples) dead_tuple_count – Số lượng tuple chết (dead tuples) chưa được dọn dẹp tuple_len – Độ dài trung bình của các tuple đang hoạt động tính bằng byte free_space – Tổng không gian trống khả dụng tính bằng byte free_percent – Tỷ lệ phần trăm không gian trống; giá trị càng cao cho thấy mức độ phình to (bloat) càng nhiều dead_tuple_len – Tổng độ dài của các dead tuple tính bằng byte dead_tuple_percent – Tỷ lệ phần trăm không gian bị chiếm dụng bởi các dead tuple Những số liệu này không chỉ là những con số đơn thuần – chúng là một hệ thống cảnh báo sớm cho các vấn đề về sức khỏe và hiệu suất của cơ sở dữ liệu. Bằng cách theo dõi các thống kê này, bạn có thể chủ động xác định các vấn đề về lưu trữ có thể đang âm thầm ảnh hưởng đến hiệu suất cơ sở dữ liệu của mình. Dù đó là tình trạng bảng bị phình to quá mức gây tốn dung lượng đĩa, hay sự phân mảnh chỉ mục làm chậm các truy vấn, pgstattuple đều giúp phát hiện những vấn đề này trước khi chúng trở thành sự cố nghiêm trọng.\nSử dụng pgstattuple trong Aurora và Amazon RDS Cả Aurora và Amazon RDS đều hỗ trợ sử dụng phần mở rộng pgstattuple. Để kích hoạt nó, trước tiên bạn cần tạo phần mở rộng trong cơ sở dữ liệu của mình bằng lệnh CREATE EXTENSION pgstattuple;. Sau khi được kích hoạt, bạn có thể sử dụng các hàm như pgstattuple(relation) để nhận thông tin chi tiết về bộ nhớ vật lý được sử dụng bởi một bảng, bao gồm số lượng trang (page), tuple sống (live tuples), tuple chết (dead tuples), và nhiều hơn nữa. Hàm pgstattuple_approx(relation) cung cấp một ước tính nhanh hơn về các số liệu này. Bạn cũng có thể nhận các thống kê về chỉ mục bằng cách sử dụng pgstatindex(index). Việc phân tích dữ liệu cấp thấp này có thể giúp xác định các bảng bị phình to (bloated) cần được vacuum, tìm các bảng có tỷ lệ tuple chết cao có thể được hưởng lợi từ việc ghi lại (rewritten), và tối ưu hóa việc sử dụng bộ nhớ vật lý của cơ sở dữ liệu của bạn.\nĐầu ra của pgstattuple cung cấp những thông tin chi tiết có thể hành động để giám sát, bảo trì và tinh chỉnh hiệu suất, như sẽ được thảo luận trong các phần sau.\nPhát hiện và quản lý sự to ra của bảng Xác định và quản lý sự phình to (bloat) là một trong những ứng dụng hữu ích nhất của pgstattuple đối với các bảng PostgreSQL. Sự phình to phát sinh khi các thao tác UPDATE và DELETE để lại không gian không sử dụng mà không được tự động thu hồi.\nPostgreSQL duy trì tính nhất quán của dữ liệu thông qua mô hình Kiểm soát đồng thời đa phiên bản (Multiversion Concurrency Control - MVCC), nơi mỗi câu lệnh SQL nhìn thấy một bản ghi nhanh (snapshot) của dữ liệu từ một thời điểm trước đó, bất kể trạng thái hiện tại của dữ liệu cơ bản. Điều này ngăn chặn các câu lệnh xem dữ liệu không nhất quán do các giao dịch đồng thời cập nhật cùng một hàng, cung cấp sự cô lập giao dịch cho mỗi phiên cơ sở dữ liệu. Không giống như các phương pháp khóa truyền thống, MVCC giảm thiểu tranh chấp khóa, cho phép hiệu suất đa người dùng hợp lý.\nKhi xóa một hàng trong các hệ thống MVCC như PostgreSQL, hàng đó không bị xóa ngay lập tức khỏi các trang dữ liệu (data pages). Thay vào đó, nó được đánh dấu là đã xóa hoặc đã hết hạn đối với giao dịch hiện tại nhưng vẫn hiển thị với các giao dịch đang xem một snapshot cũ hơn, tránh xung đột. Khi các giao dịch hoàn tất, các tuple chết hoặc hết hạn này dự kiến sẽ được vacuum và không gian sẽ được thu hồi. Trong PostgreSQL, một thao tác UPDATE tương đương với sự kết hợp của DELETE và INSERT. Khi một hàng được cập nhật, PostgreSQL đánh dấu phiên bản cũ là đã hết hạn (giống như một DELETE) nhưng vẫn giữ cho nó hiển thị với các snapshot giao dịch cũ hơn. Sau đó, nó chèn một phiên bản mới của hàng với các giá trị được cập nhật (giống như một INSERT). Theo thời gian, các phiên bản hàng đã hết hạn sẽ tích tụ cho đến khi quy trình VACUUM loại bỏ chúng, thu hồi lại không gian. Cách tiếp cận này cho phép mô hình MVCC của PostgreSQL, cung cấp sự cô lập snapshot mà không cần khóa rõ ràng trong quá trình cập nhật.\nAutovacuum của PostgreSQL là một quy trình bảo trì tự động giúp thu hồi bộ nhớ bị chiếm dụng bởi các tuple chết và cập nhật các thống kê được bộ lập kế hoạch truy vấn (query planner) sử dụng. Quy trình autovacuum sẽ kích hoạt khi tuổi tối đa (tính bằng số giao dịch) vượt qua autovacuum_freeze_max_age, hoặc khi đạt đến ngưỡng: autovacuum_vacuum_threshold + autovacuum_vacuum_scale_factor * số lượng tuple. Trong công thức này, autovacuum_vacuum_threshold đại diện cho số lượng tối thiểu các tuple được cập nhật hoặc xóa cần thiết để bắt đầu dọn dẹp, trong khi autovacuum_vacuum_scale_factor là một phần kích thước của bảng được thêm vào phép tính ngưỡng để xác định khi nào việc bảo trì nên diễn ra. Nếu autovacuum không dọn dẹp được các tuple chết vì một số lý do nhất định, bạn có thể cần phải xử lý các bảng bị phình to nghiêm trọng theo cách thủ công.\nCác tuple chết được lưu trữ cùng với các tuple sống trong các trang dữ liệu. Sự phình to cũng có thể là do không gian trống trong các trang, ví dụ như sau khi autovacuum đã dọn dẹp các tuple chết. Trong quá trình thực thi truy vấn, PostgreSQL quét nhiều trang hơn chứa đầy các tuple chết, gây ra I/O tăng và các truy vấn chậm hơn. Các bảng bị phình to nghiêm trọng làm cho khối lượng công việc của cơ sở dữ liệu tiêu thụ I/O đọc không cần thiết, ảnh hưởng đến hiệu suất ứng dụng. Việc dọn dẹp sự phình to có thể là cần thiết nếu autovacuum thất bại.\nTrước khi chúng ta đi sâu vào việc phân tích sự phình to của bảng với pgstattuple, hãy đảm bảo bạn đã thiết lập mọi thứ để có thể làm theo. Bạn sẽ cần quyền truy cập vào một phiên bản Amazon RDS hoặc Aurora PostgreSQL, cũng như một máy khách đã cài đặt psql và được cấu hình đúng cách để kết nối với cơ sở dữ liệu của bạn. Hãy chắc chắn rằng bạn có các quyền cần thiết để tạo bảng và cài đặt các phần mở rộng trong môi trường PostgreSQL của mình. Đối với phần trình diễn này, chúng tôi sẽ sử dụng bảng pgbench_accounts. Nếu bạn chưa có bảng này, bạn có thể dễ dàng tạo nó bằng tiện ích pgbench. Chạy lệnh pgbench -i -s 10 để khởi tạo một lược đồ pgbench với hệ số tỷ lệ là 10, điều này sẽ tạo ra bảng pgbench_accounts cùng với các bảng cần thiết khác. Điều này sẽ cung cấp cho chúng ta dữ liệu mẫu để làm việc trong quá trình phân tích. Ngoài ra, bạn nên cài đặt phần mở rộng pgstattuple trên phiên bản cơ sở dữ liệu của mình. Nếu bạn chưa cài đặt nó, bạn có thể làm như vậy bằng cách chạy CREATE EXTENSION pgstattuple; với tư cách là người dùng có đủ đặc quyền. Với các điều kiện tiên quyết này, bạn sẽ sẵn sàng khám phá phân tích sự phình to của bảng bằng cách sử dụng dữ liệu thực trong một môi trường được kiểm soát.\nMặc dù pgstattuple cung cấp phân tích toàn diện về sự phình to của bảng, nó có thể tiêu tốn nhiều tài nguyên. Chúng tôi khuyên bạn nên sử dụng trước các truy vấn ước tính sự phình to nhẹ hơn được ghi nhận tại đây. Nếu cần phân tích chi tiết hơn, đây là cách sử dụng pgstattuple. Ví dụ sau đây minh họa cách sử dụng pgstattuple để phân tích thông tin về sự phình to trong một bảng.\nTạo bảng pgbench_accounts_test với 10,000 bản ghi: Trong ví dụ này, truy vấn pgstattuple trả về số lượng tuple chết là 0 và kích thước bảng là 1672kB: Để chứng minh cách sử dụng pgstattuple, chúng tôi tắt tính năng tự động hút chân không (không khuyến khích trong môi trường sản xuất) và cập nhật 2.500 bản ghi: Bây giờ, dữ liệu pgstattuple của bảng này cho thấy 2.500 bộ dữ liệu phiên bản cũ được chuyển sang bộ dữ liệu đã chết. bloat_percentage trong PostgreSQL đề cập đến tỷ lệ không gian có thể được thu hồi trong một bảng hoặc chỉ mục so với tổng kích thước của nó. Nó có thể được tính toán bằng cách sử dụng dữ liệu từ pgstattuple như sau: Giá trị bloat_percentage vượt quá 30%–40% thường cho thấy tình trạng bloat có vấn đề cần được xử lý. Để dọn dẹp bloat, hãy sử dụng lệnh VACUUM: Chúng ta hãy kiểm tra dữ liệu pgstattuple sau thao tác VACUUM: Thao tác VACUUM sẽ đặt lại dead_tuple_count về 0. Không gian trống vẫn còn gắn liền với bảng sẽ có sẵn cho các thao tác chèn (INSERT) hoặc cập nhật (UPDATE) trong cùng một bảng. Điều này làm cho table_len (độ dài bảng) không thay đổi ngay cả sau khi thực hiện thao tác VACUUM.\nĐể thu hồi dung lượng đĩa bị chiếm dụng bởi sự phình to (bloat), có hai lựa chọn:\nVACUUM FULL – VACUUM FULL có thể thu hồi nhiều dung lượng đĩa hơn nhưng chạy chậm hơn nhiều. Nó yêu cầu một khóa ACCESS EXCLUSIVE (khóa truy cập độc quyền) trên bảng mà nó đang xử lý, và do đó không thể thực hiện song song với các hoạt động sử dụng khác của bảng. Mặc dù các thao tác VACUUM FULL thường không được khuyến khích trong môi trường sản xuất (production), chúng có thể chấp nhận được trong các cửa sổ bảo trì đã được lên lịch, nơi thời gian chết (downtime) đã được lên kế hoạch và phê duyệt.\npg_repack – pg_repack là một phần mở rộng của PostgreSQL giúp loại bỏ hiệu quả sự phình to của bảng và chỉ mục trong khi vẫn duy trì tính sẵn sàng trực tuyến (online). Không giống như CLUSTER và VACUUM FULL, nó giảm thiểu thời gian khóa độc quyền trong quá trình xử lý, mang lại hiệu suất tương đương với CLUSTER. Mặc dù pg_repack cho phép sắp xếp lại bảng và chỉ mục trực tuyến với thời gian chết của ứng dụng ở mức tối thiểu, điều quan trọng là phải xem xét các hạn chế của nó. Phần mở rộng này vẫn yêu cầu các khóa độc quyền ngắn trong quá trình hoạt động và có thể gặp khó khăn để hoàn thành trên các bảng có giao dịch tốc độ cao, có khả năng ảnh hưởng đến hiệu suất cơ sở dữ liệu. Đối với các bảng được sử dụng nhiều, nơi việc đóng gói lại toàn bộ (full repacking) gặp khó khăn, hãy xem xét phương án thay thế là chỉ đóng gói lại chỉ mục (index-only repacking). Các phương pháp hay nhất bao gồm kiểm thử kỹ lưỡng trong môi trường không phải sản xuất, lập lịch vào các khoảng thời gian có lưu lượng truy cập thấp, và có sẵn một kế hoạch giám sát và khôi phục (rollback). Mặc dù có những lợi ích, người dùng nên nhận thức được những rủi ro tiềm ẩn và lập kế hoạch phù hợp khi triển khai pg_repack trong môi trường PostgreSQL của họ. Hoạt động VACUUM FULL giảm table_len:\nThao tác VACUUM FULL sẽ lấy lại dung lượng bị lãng phí vào bộ nhớ đĩa và giảm table_len. Truy vấn sau đây xác định độ phình của 10 bảng lớn nhất trong cơ sở dữ liệu của bạn bằng pgstattuple. pgstattuple thực hiện quét toàn bộ bảng và có thể tiêu tốn nhiều tài nguyên của phiên bản như CPU ​​và I/O hơn. Điều này làm cho hoạt động của pgstattuple chậm hơn đối với các bảng lớn. Ngoài ra, hàm pgstattuple_approx(relation) cung cấp ước tính nhanh hơn về các số liệu này. Mặc dù ít tốn tài nguyên hơn pgstattuple, nhưng nó vẫn có thể gây khó khăn cho các bảng rất lớn hoặc hệ thống bận rộn. Hãy cân nhắc chạy vào giờ thấp điểm hoặc trên một bản sao nếu có.\nTự động hóa việc vacuum thủ công Việc thường xuyên theo dõi sự phình to (bloat) cho phép bạn chủ động xác định các nhu cầu bảo trì, trước khi hiệu suất bị ảnh hưởng. Các số liệu về sự phình to cũng có thể giúp tinh chỉnh các cài đặt autovacuum để dọn dẹp không gian một cách quyết liệt hơn nếu cần. Sau khi bạn xác định 10 bảng bị phình to nhiều nhất, bạn có thể tự động hóa thao tác VACUUM bằng cách sử dụng phần mở rộng pg_cron. pg_cron là một trình lập lịch công việc dựa trên cron cho PostgreSQL, chạy bên trong cơ sở dữ liệu như một phần mở rộng. Nó sử dụng cú pháp tương tự như cron thông thường, nhưng cho phép bạn lập lịch các lệnh PostgreSQL trực tiếp từ cơ sở dữ liệu. Đoạn mã sau đây là một ví dụ về việc sử dụng hàm cron.schedule của pg_cron để thiết lập một công việc chạy VACUUM trên một bảng cụ thể vào lúc 23:00 (GMT) hàng ngày: Chẩn đoán và giải quyết tình trạng phình to của chỉ mục Giống như bảng, các chỉ mục (index) trong PostgreSQL cũng có thể bị phình to, gây lãng phí không gian và ảnh hưởng đến hiệu suất. pgstattuple cho phép phát hiện tình trạng phình to của chỉ mục bằng cách sử dụng pgstatindex.\nTruy vấn sau đây hiển thị mã định danh của chỉ mục, tổng kích thước chỉ mục tính bằng byte và mật độ lá trung bình (average leaf density):\nMật độ lá trung bình là tỷ lệ phần trăm dữ liệu hữu ích trong các trang lá (leaf pages) của chỉ mục. Các chỉ mục bị phình to đáng kể có thể được xây dựng lại bằng lệnh REINDEX hoặc pg_repack để loại bỏ không gian chết và khôi phục hiệu suất tối ưu. Khuyến nghị nên kiểm tra định kỳ tình trạng phình to đối với các chỉ mục bận rộn, có tỷ lệ thay đổi cao.\nĐánh giá sự phân mảnh của chỉ mục Một công dụng giá trị khác của pgstattuple là xác định các vấn đề về phân mảnh chỉ mục. Sự phân mảnh xảy ra khi các trang chỉ mục (index pages) trở nên rải rác do các thao tác xóa, cập nhật và chia tách trang (page splits). Các chỉ mục bị phân mảnh nhiều có nhiều tuple chết chiếm dụng không gian một cách không hiệu quả. Chúng ta có thể kiểm tra mức độ phân mảnh bằng cách sử dụng leaf_fragmentation: Nếu leaf_fragmentation cao, chỉ mục có khả năng đã bị phân mảnh và nên xem xét việc thực hiện REINDEX. Việc xây dựng lại sẽ loại bỏ sự phân mảnh và các chi phí hiệu suất liên quan.\nCác phương pháp hay nhất khi sử dụng pgstattuple Hãy xem xét các phương pháp hay nhất sau đây khi sử dụng pgstattuple để giám sát và bảo trì PostgreSQL:\nĐể ước tính sự phình to (bloat) trong các bảng PostgreSQL, hãy sử dụng truy vấn check_postgres được đề cập trên wiki của PostgreSQL. Sử dụng phần mở rộng pgstattuple để phân tích lưu trữ vật lý của các bảng cơ sở dữ liệu, cung cấp các thống kê chi tiết về việc sử dụng không gian trong cơ sở dữ liệu, bao gồm cả lượng không gian bị lãng phí do phình to. Xây dựng lại các bảng và chỉ mục bị phình to đáng kể để thu hồi không gian chết. Theo dõi chỉ số dead_tuple_percent cao để xác định các vấn đề về phân mảnh. Tập trung bảo trì vào các bảng và chỉ mục quan trọng đối với hiệu suất của khối lượng công việc. Tránh chạy pgstattuple trên các bảng có hoạt động cao để ngăn chặn sự can thiệp. Sử dụng các số liệu của pgstattuple để tinh chỉnh cài đặt autovacuum. Kết hợp pgstattuple với phân tích truy vấn và nhật ký (logs) để có cái nhìn toàn diện về cơ sở dữ liệu. Kết luận Phần mở rộng pgstattuple đóng vai trò như một công cụ mạnh mẽ để khám phá các số liệu chẩn đoán quan trọng trong cơ sở dữ liệu PostgreSQL, tiết lộ các thống kê lưu trữ chi tiết giúp các nhóm xác định và giải quyết các vấn đề ảnh hưởng đến hiệu suất như phình to và phân mảnh chỉ mục. Hoạt động liền mạch với Aurora và RDS PostgreSQL, phần mở rộng này cung cấp khả năng hiển thị cần thiết về các mẫu lưu trữ và yêu cầu bảo trì.\nViệc tuân theo các phương pháp hay nhất của pgstattuple là chìa khóa để duy trì cơ sở dữ liệu PostgreSQL hiệu quả, hiệu suất cao, và các tổ chức có thể nâng cao hơn nữa việc quản lý cơ sở dữ liệu của mình thông qua các tùy chọn hỗ trợ của AWS – các khách hàng của AWS Enterprise Support, Enterprise On-Ramp, và Business Support có thể tận dụng các cam kết AWS Countdown Premium để được hướng dẫn tối ưu hóa, cho phép các nhóm tự tin triển khai các phương pháp hay nhất và duy trì hiệu suất tối ưu trong khi tập trung vào các mục tiêu kinh doanh cốt lõi của họ.\nThông tin tác giả Vivek Singh Vivek Singh là Chuyên gia Cơ sở dữ liệu Chính, Quản lý Tài khoản Kỹ thuật tại AWS, tập trung vào Amazon RDS cho PostgreSQL và các công cụ Amazon Aurora PostgreSQL. Ông làm việc với các khách hàng doanh nghiệp, cung cấp hỗ trợ kỹ thuật về hiệu suất vận hành PostgreSQL và chia sẻ các phương pháp hay nhất về cơ sở dữ liệu. Ông có hơn 17 năm kinh nghiệm trong các giải pháp cơ sở dữ liệu nguồn mở và rất thích làm việc với khách hàng để giúp thiết kế, triển khai và tối ưu hóa khối lượng công việc cơ sở dữ liệu quan hệ trên AWS.\nKiran Singh Kiran Singh là Kiến trúc sư Giải pháp Đối tác Cấp cao và là chuyên gia về Amazon RDS và Amazon Aurora tại AWS, tập trung vào cơ sở dữ liệu quan hệ. Cô giúp khách hàng và đối tác xây dựng các giải pháp được tối ưu hóa cao, có khả năng mở rộng và bảo mật; hiện đại hóa kiến trúc của họ; và di chuyển khối lượng công việc cơ sở dữ liệu của họ sang AWS.\nSagar Patel Sagar Patel là Kiến trúc sư Chuyên ngành Cơ sở dữ liệu Chính của nhóm Dịch vụ Chuyên nghiệp tại Amazon Web Services. Ông làm việc với tư cách là chuyên gia di chuyển cơ sở dữ liệu, cung cấp hướng dẫn kỹ thuật và hỗ trợ khách hàng Amazon di chuyển cơ sở dữ liệu tại chỗ của họ sang AWS.\n"},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/5-workshop/5.1-workshop-overview/","title":"Giới thiệu","tags":[],"description":"","content":"ApexEV — Giới thiệu Workshop (Tóm tắt) ApexEV là nền tảng quản lý gara xe điện cấp doanh nghiệp, số hóa hoạt động xưởng, cải thiện trải nghiệm khách hàng và giúp kỹ thuật viên làm việc nhanh hơn, an toàn hơn.\nTại sao làm workshop này:\nGiải quyết các vấn đề thường gặp tại gara: quy trình thủ công, thiếu minh bạch, chăm sóc khách hàng kém và rủi ro dữ liệu. Xây dựng backend trên cloud bảo mật, có khả năng mở rộng và tối ưu chi phí ngay từ đầu theo best practices của AWS. Tóm tắt kiến trúc chính:\nFrontend: Ứng dụng React host trên AWS Amplify (CI/CD + CloudFront). Backend: Các service Spring Boot chạy trên ECS (Fargate) — container không cần quản lý server. Cơ sở dữ liệu: Amazon RDS (private subnets, backup tự động, mã hóa KMS). Lưu trữ: Amazon S3 cho media (dùng presigned URLs để upload trực tiếp). API \u0026amp; Bất đồng bộ: API Gateway làm ingress HTTPS; SNS → Lambda → SES cho email; Lambda → Bedrock cho AI/chat. Mạng \u0026amp; Bảo mật: VPC (public/private), Security Groups, VPC Endpoints, WAF và IAM theo nguyên tắc least-privilege. Lợi ích chính:\nƯu tiên bảo mật: backend và DB ở private; edge service terminate TLS và áp dụng WAF/rate limits. Tối ưu chi phí: Fargate + Lambda tính phí theo sử dụng; lifecycle rules và autoscaling giúp tiết giảm chi phí. Hiện đại \u0026amp; mô-đun: tách biệt frontend/backend, luồng bất đồng bộ giúp tăng chịu lỗi và khả năng mở rộng. Mục tiêu workshop:\nCấu hình mạng và dịch vụ an toàn, triển khai frontend + backend, kết nối RDS và S3, tích hợp pipeline email và AI. Mỗi module có các bước hướng dẫn, cấu hình khuyến nghị và hướng dẫn dọn dẹp. "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Lộ trình thực tập được chia thành ba giai đoạn chính:\nKiến thức nền tảng: Nắm vững các dịch vụ cốt lõi của AWS (Mạng, Tính toán, Lưu trữ, Bảo mật) và Toán học cho Machine Learning. Nghiên cứu chuyên sâu: Đi sâu vào NLP, Transformers và Generative AI (AWS Bedrock). Triển khai dự án: Thiết kế kiến trúc hệ thống, Phát triển Full-stack và Triển khai Serverless. Dưới đây là danh sách các công việc và kết quả đạt được theo từng tuần:\nTuần 1: Làm quen với Điện toán đám mây \u0026amp; Thiết lập tài khoản AWS\nTuần 2: Chuyên sâu về AWS Networking: VPC \u0026amp; Bảo mật mạng\nTuần 3: Compute, Kết nối mạng nâng cao (Transit Gateway) \u0026amp; Nhập môn NLP\nTuần 4: Giải pháp Hybrid Cloud, Storage Gateway \u0026amp; Toán học cho NLP\nTuần 5: Lưu trữ nâng cao, Tự động hóa bảo mật \u0026amp; Thuật toán NLP\nTuần 6: Thiết kế kiến trúc Cloud, Bảo mật định danh \u0026amp; Attention Models\nTuần 7: Cơ sở dữ liệu, Prototyping Chatbot AI \u0026amp; Khởi động dự án\nTuần 8: Tích hợp hệ thống, Thi giữa kỳ \u0026amp; Viết Proposal\nTuần 9: Transformers, LLMs \u0026amp; Generative AI với AWS Bedrock\nTuần 10: Fine-tuning BERT, Tối ưu hóa Serverless \u0026amp; Hoàn thiện UI\nTuần 11: Hoàn thiện tài liệu, Triển khai thực tế \u0026amp; Đồng bộ hóa kiến trúc\nTuần 12: Tổng kết cuối kỳ, Sửa lỗi \u0026amp; Demo sản phẩm\n"},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/5-workshop/5.4-databaseandstorage/5.4.1-create-rds/","title":"Tạo RDS","tags":[],"description":"","content":" Mở trang Amazon Aurora and RDS\nỞ thanh điều hướng bên trái, chọn Databases, sau đó nhấp Create database Trong màn hình tạo, chọn Full configuration\nChọn loại cơ sở dữ liệu là MySQL\nChọn Templates là Production Ở phần Availability and durability, chọn Multi-AZ DB cluster deployment (3 instances)\nĐiền DB instance identifier\nChọn chế độ Self managed\nNhập Master password Trong Instance configuration, chọn db.m5d.large\nTrong Storage, đặt Allocated storage là 100 và Provisioned IOPS là 1000\nTrong Connectivity, chọn Don\u0026rsquo;t connect to an EC2, sau đó chọn VPC Chọn DB subnet group và ở phần VPC security group (firewall) chọn Choose existing\nChọn rds-sg\nSau đó nhấp Create database "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/5-workshop/5.3-vpc/5.3.1-create-route-table/","title":"Tạo Route Table và Internet Gateway","tags":[],"description":"","content":" Route Table là một tập hợp các quy tắc (routes) được router sử dụng để xác định đường đi tốt nhất cho các gói dữ liệu tới đích.\nMở Amazon VPC console Chọn Route tables, sau đó nhấp Create route table Trong màn hình Create route table: Nhập tên cho Route table Chọn VPC đã tạo Sau đó nhấp Create route table Trong bảng Route table, nhấp vào Route table vừa tạo Chọn Routes ở thanh điều hướng -\u0026gt; nhấp Edit routes Ở màn hình Edit routes -\u0026gt; chọn Target là local -\u0026gt; Save changes Chọn Internet Gateway trên thanh điều hướng bên trái -\u0026gt; nhấp Create internet gateway Trong Create Internet Gateway: Nhập tên cho Internet Gateway Nhấp Create internet gateway Quay lại Route table -\u0026gt; Thực hiện tạo route table giống bước 3 Chọn Route table này -\u0026gt; Edit routes Ở Target chọn Internet Gateway vừa tạo Sau đó nhấp Save changes "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/1-worklog/1.1-week1/","title":"Worklog Tuần 1","tags":[],"description":"","content":"Mục tiêu tuần 1: Hòa nhập nhanh chóng với văn hóa làm việc tại AWS và làm quen với các bạn mới trong quá trình OJT tại First Cloud Journey (FCJ). Nắm vững kiến thức nền tảng về các dịch vụ AWS cốt lõi (Core Services). Tập thao tác trên AWS Management Console. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu sơ bộ về AWS - Tìm hiểu lưu ý các nội quy, quy định tại đơn vị thực tập 09/08/2025 09/08/2025 3 - Tìm hiểu AWS thông qua module 1 + Hạ tầng AWS + Công cụ quản lý AWS + Tối ưu chi phí - Thực hành: Tạo tài khoản AWS 09/09/2025 09/09/2025 https://cloudjourney.awsstudygroup.com/ https://www.youtube.com/watch?v=HxYZAK1coOI https://www.youtube.com/watch?v=IK59Zdd1poE https://www.youtube.com/watch?v=HSzrWGqo3ME https://www.youtube.com/watch?v=pjr5a-HYAjI https://www.youtube.com/watch?v=2PQYqH_HkXw https://www.youtube.com/watch?v=IY61YlmXQe8 https://www.youtube.com/watch?v=Hku7exDBURo 4 - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Thao tác với AWS Console + Thiết lập MFA và IAM + Cài AWS CLI \u0026amp; cấu hình 09/10/2025 09/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu về EC2: + Các loại Instance + Lưu trữ: EBS (Elastic Block Store) và Instance Store (Ephemeral Storage) + Mạng \u0026amp; Bảo mật: Security Groups, Key Pairs và Public IP vs Private IP vs Elastic IP + IAM Role + Tìm hiểu SSH 09/11/2025 09/11/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Khởi tạo một EC2 + Kết nối vào EC2 đó thông qua SSH 09/12/2025 09/12/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 1: Nắm vững các nội quy, quy định làm việc tại đơn vị thực tập FCJ.\nHiểu tổng quan về kiến trúc hạ tầng toàn cầu của AWS, các công cụ quản lý và các nguyên tắc tối ưu hóa chi phí (Module 1).\nĐã tạo và kích hoạt thành công tài khoản AWS Free Tier.\nLàm quen với AWS Management Console, thực hiện thiết lập bảo mật tài khoản:\nCấu hình MFA (Multi-Factor Authentication). Tạo và quản lý IAM User/Group cơ bản. Cài đặt và cấu hình thành công AWS CLI trên máy tính cá nhân.\nNắm vững kiến thức nền tảng về dịch vụ Amazon EC2, bao gồm:\nPhân loại các Instance (Instance Types). Các tùy chọn lưu trữ: Phân biệt EBS (Elastic Block Store) và Instance Store. Cơ chế mạng \u0026amp; bảo mật: Security Groups, Key Pairs, phân biệt Public/Private/Elastic IP. Vai trò của IAM Role trong việc ủy quyền truy cập. Thực hành thành công với dịch vụ EC2:\nKhởi tạo một EC2 Instance hoàn chỉnh. Sử dụng giao thức SSH để kết nối và thao tác với Instance từ máy trạm. "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/1-worklog/1.2-week2/","title":"Worklog Tuần 2","tags":[],"description":"","content":"Mục tiêu tuần 2: Hiểu sâu về kiến trúc mạng AWS: VPC, các tính năng bảo mật và mô hình Multi-VPC. Nắm vững các khái niệm kết nối mạng nâng cao: VPN, DirectConnect và LoadBalancer. Thực hành xây dựng hệ thống mạng hoàn chỉnh: Subnet, Route Table, Internet Gateway, Security Group và Network ACLs. Kết nối và thiết lập làm việc nhóm với các thành viên dự án cuối kỳ. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu về AWS Virtual Private Cloud (VPC) - Tìm hiểu về VPC Security and Multi-VPC features 15/09/2025 15/09/2025 https://www.youtube.com/watch?v=O9Ac_vGHquM https://www.youtube.com/watch?v=BPuD1l2hEQ4\u0026t 3 - Tìm hiểu VPN - DirectConnect - LoadBalancer - ExtraResources 16/09/2025 16/09/2025 https://www.youtube.com/watch?v=CXU8D3kyxIc\u0026t 4 - Thực hành: + Làm quen với VPC + Xây dựng Subnet + Tìm hiểu Route Table và Internet Gateway 17/09/2025 17/09/2025 https://www.youtube.com/watch?v=dHoYmQR7FYs https://www.youtube.com/watch?v=XBJgHS3XQjk 5 - Tìm hiểu và thực hành Security Group - Tìm hiểu và thực hành Network ACLs - Tìm hiểu và thực hành VPC Resource Map 18/09/2025 18/09/2025 https://www.youtube.com/watch?v=B1qxOQLmavQ https://www.youtube.com/watch?v=GVDsDu9dOFY\u0026t https://www.youtube.com/watch?v=fZa_kQ69stI 6 - Ôn tập lại những gì đã học trong tuần - Mở rộng tìm hiểu thêm về VPC - Meeting gặp gỡ và làm quen với các thành viên trong nhóm làm dự án cuối kì 19/09/2025 19/09/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 2: Hiểu rõ và phân biệt được các thành phần cốt lõi trong Amazon VPC:Hiểu rõ và phân biệt được các thành phần cốt lõi trong Amazon VPC:\nCIDR block Subnet (Public vs Private) Route Table \u0026amp; Internet Gateway (IGW) Nắm được các giải pháp kết nối mạng và phân phối tải:\nVPN \u0026amp; DirectConnect Load Balancer Thiết lập và quản lý các lớp bảo mật mạng (Network Security):\nSecurity Group: Cấu hình firewall mức Instance (Stateful). Network ACLs: Cấu hình firewall mức Subnet (Stateless). Sử dụng thành thạo công cụ VPC Resource Map để trực quan hóa và kiểm soát luồng đi của tài nguyên trong mạng.\nĐã hoàn thành buổi meeting đầu tiên với nhóm dự án.\n"},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/1-worklog/1.3-week3/","title":"Worklog Tuần 3","tags":[],"description":"","content":"Mục tiêu Tuần 3: Nắm vững các dịch vụ tính toán EC2: Vòng đời, Lưu trữ (EBS/Instance Store), và Tự động mở rộng (Auto Scaling). Triển khai kết nối nâng cao sử dụng AWS Transit Gateway. Triển khai các giải pháp lưu trữ và phân phối nội dung có khả năng mở rộng (S3 \u0026amp; CloudFront). Tìm hiểu các khái niệm nền tảng về AI/ML (NLP, Phân tích cảm xúc) cho dự án cuối khóa. Phối hợp với nhóm để thảo luận và chốt ý tưởng cho dự án cuối khóa. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tạo EC2 Instances trong Subnets - Thực hành tạo Internet Gateway - Tìm hiểu về Transit Gateway Route Tables - Cài đặt Transit Gateway - Kết nối EC2 Instance tới Endpoint 22/09/2025 22/09/2025 https://www.youtube.com/@AWSStudyGroup/ https://cloudjourney.awsstudygroup.com/ 3 - Tìm hiểu thêm về EC2 + AMI/ Backup/ Key pair + Elastic block store + Instances store + User data \u0026amp; meta data + EC2 auto scaling\n23/09/2025 23/09/2025 https://cloudjourney.awsstudygroup.com/ https://www.youtube.com/@AWSStudyGroup/ 4 - Triển khai hạ tầng - Tạo Backup plan - Tiến hành kiếm thử khôi phục - Dọn dẹp tài nguyên - Tạo S3 Bucket 24/09/2025 24/09/2025 https://cloudjourney.awsstudygroup.com/ https://www.youtube.com/@AWSStudyGroup/ 5 - Tạo EC2 cho Storage Gateway - Thực hành tạo thử 1 website tĩnh đơn giản - Cấu hình public access block và public objects - Tìm hiểu về AWS CloudFont và thực hành cấu hinh cho CloudFont 25/09/2025 25/09/2025 https://cloudjourney.awsstudygroup.com/ https://www.youtube.com/@AWSStudyGroup/ 6 - Tìm hiểu Supervised ML \u0026amp; Sentiment Analysis - Natural Language preprocessing - Visualizing tweets and Logistic Regression models - Meeting nhóm để lên ý tưởng cho dự án cuối kì 26/09/2025 26/09/2025 https://www.coursera.org/learn/classification-vector-spaces-in-nlp/ Thành tựu Tuần 3: Đã quản lý và tối ưu hóa thành công các EC2 Instances:\nCấu hình AMIs, Key Pairs, và User Data/Meta Data. Phân biệt được sự khác nhau giữa Elastic Block Store (EBS) và Instance Store. Triển khai EC2 Auto Scaling để đảm bảo tính sẵn sàng cao. Xây dựng các cấu trúc mạng phức tạp sử dụng AWS Transit Gateway để kết nối các VPC.\nThực hiện các hoạt động Khôi phục sau thảm họa và Lưu trữ:\nTạo các Backup plans và thực hiện kiểm thử khôi phục thành công. Triển khai một Website tĩnh sử dụng S3 Buckets. Cấu hình các cài đặt Truy cập công khai và Object permissions. Tối ưu hóa hiệu suất phân phối nội dung:\nTích hợp AWS CloudFront (CDN) với S3 để giảm độ trễ và cải thiện tốc độ truy cập. Bước đầu tiếp cận với Machine Learning (NLP):\nHiểu các khái niệm về Học máy có giám sát (Supervised ML) \u0026amp; Phân tích cảm xúc. Thực hành tiền xử lý Ngôn ngữ tự nhiên và trực quan hóa Hồi quy Logistic. Xác định khái niệm ban đầu cho dự án cuối khóa. "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/1-worklog/1.4-week4/","title":"Worklog Tuần 4","tags":[],"description":"","content":"Mục tiêu Tuần 4: Nắm vững quy trình Hybrid Cloud: Nhập/Xuất Máy ảo (VMs) và tích hợp lưu trữ tại chỗ (On-premises). Đào sâu kiến thức về AWS Storage (EFS, FSx, Storage Gateway) và Compute (Autoscaling, Lightsail). Xây dựng nền tảng toán học cho Xử lý ngôn ngữ tự nhiên (NLP): Không gian Vector, Xác suất và Đại số tuyến tính. Chốt ý tưởng dự án cuối kỳ và thiết lập khung tài liệu sử dụng Hugo. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu về EC2 Autoscaling - EFS/FSx - Lightsail - Bổ sung thêm kiến thức về Basic Storage \u0026amp; Compute services on AWS - Tìm hiểu về Probability and Bayes’ Rule 29/09/2025 29/09/2025 https://www.youtube.com/@AWSStudyGroup/ https://www.coursera.org/learn/classification-vector-spaces-in-nlp/ 3 - Tìm hiểu mở rộng về các dịch vụ Database and Security trên AWS - Tìm hiểu VMWare Workstation - Thực hành xuất Virtual Machine từ On-premises - Thực hành upload Virtual Machine lên AWS 30/09/2025 30/09/2025 https://www.youtube.com/@AWSStudyGroup/ 4 - Học về Linear algebra in Python with Numpy - Học Euclidean Distance \u0026amp; Cosine Similarity - Tìm hiểu Manipulating Words in Vector Spaces - Thực hành các bài lab code về Vector Space Model 01/10/2025 01/10/2025 https://www.coursera.org/learn/classification-vector-spaces-in-nlp/ 5 - Nhập Virtual Machine vào AWS - Triển khai Instance từ AMI - Thiết lập ACL bucket S3 - Xuất máy ảo từ Instance - Dọn dẹp tài nguyên trên AWS Cloud - Tạo cổng lưu trữ - Mount File shares on On-premises machine 02/10/2025 02/10/2025 https://www.youtube.com/@AWSStudyGroup/ 6 - Tìm hiểu về Hugo Theme - Tim hiểu cách viết Workshop báo cáo cuối kì - Meeting tổng kết và đưa ra ý tưởng cuối cùng cho báo cáo cuối kì cùng nhóm 03/10/2025 03/10/2025 https://www.youtube.com/@AWSStudyGroup/ Thành tựu Tuần 4: Đã triển khai thành công các chiến lược Hybrid Cloud:\nXuất các máy ảo (VMs) từ VMWare Workstation cục bộ và tải chúng lên AWS. Nhập các máy ảo (VMs) để tạo AMIs và khởi chạy các Instances hoạt động. Xuất các AWS Instances trở lại môi trường cục bộ. Cấu hình các Giải pháp Lưu trữ Nâng cao:\nTriển khai AWS Storage Gateway. Gắn kết (mount) thành công các chia sẻ tệp AWS trực tiếp lên các máy tại chỗ (on-premises). Quản lý S3 Access Control Lists (ACLs) để bảo mật chi tiết. Ứng dụng Nền tảng Toán học cho NLP (Machine Learning):\nSử dụng Python (Numpy) cho các phép toán Đại số tuyến tính. Tính toán Khoảng cách Euclid \u0026amp; Độ tương đồng Cosine để phân tích văn bản. Hiểu và áp dụng Định lý Bayes và Mô hình Không gian Vector. Sự sẵn sàng cho Dự án \u0026amp; Tài liệu:\nĐạt được sự thống nhất về ý tưởng dự án cuối khóa với nhóm. "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/1-worklog/1.5-week5/","title":"Worklog Tuần 5","tags":[],"description":"","content":"Mục tiêu Tuần 5: Nắm vững các thuật toán NLP nâng cao: Biến đổi Vector, K-láng giềng gần nhất (KNN), và Bảng băm (Hash tables). Đi sâu vào hệ sinh thái Lưu trữ AWS: Các tính năng nâng cao của S3, Glacier, Snow Family, và các chiến lược Sao lưu. Triển khai tuân thủ Bảo mật và Tự động hóa: Security Hub, IAM Roles, và AWS Lambda. Hoàn thiện kế hoạch thực hiện chi tiết cho dự án cuối kỳ. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Học về Transforming word vectors - Tìm hiểu K-nearest neighbors - Tìm hiểu về Hash tables and hash functions - Làm lab code Word Translation 06/10/2025 06/10/2025 https://www.coursera.org/learn/classification-vector-spaces-in-nlp/ 3 - Tìm hiểu Dịch vụ lưu trữ trên AWS - Tìm hiểu về Amazon Simple Storage Service ( S3 ) - Access Point - Storage Class - Tìm hiểu về S3 Static Website \u0026amp; CORS - Control Access - Object Key \u0026amp; Performance - Glacier - Tìm hiểu về Snow Family - Storage Gateway - Backup 07/10/2025 07/10/2025 https://www.youtube.com/@AWSStudyGroup/ 4 - Làm lab Module 05 + Enable Security Hub + Score for each set of criteria + Dọn dẹp tài nguyên + Tạo VPC + Tạo Security Group và EC2 Instance + Tạo tag cho Instance + Tạo role cho lambda + Tạo lambda Function + Kiểm tra kết quả và dọn dẹp tài nguyên 08/10/2025 08/10/2025 https://www.youtube.com/@AWSStudyGroup/ 5 - Dịch Blog - Meeting xây dựng kế hoạch cho dự án cuối kì - Làm lab Module05-28 - Làm lab Module05-29 - Làm lab Module05-30 - Làm lab Module05-30 09/10/2025 09/10/2025 https://www.youtube.com/@AWSStudyGroup/ 6 - Làm lab Module05-31 - Làm lab Module05-32 - Làm lab Module05-33 - Meeting nhóm tổng kết lại kế hoạch xây dựng dự án cuối kì - Ôn tập lại kiến thức của tuần qua 10/10/2025 10/10/2025 https://www.youtube.com/@AWSStudyGroup/ Thành tựu Tuần 5: Nắm vững số học Không gian Vector trong NLP:\nTriển khai KNN và Bảng băm. Lập trình thành công mô hình Dịch thuật Từ sử dụng biến đổi vector. Cấu hình các Kiến trúc Lưu trữ AWS Nâng cao:\nTriển khai các Website tĩnh trên S3 với cấu hình CORS. Quản lý các Lớp lưu trữ S3 (Storage Classes) và Kiểm soát truy cập. Hiểu về di chuyển dữ liệu ngoại tuyến sử dụng AWS Snow Family. Triển khai Bảo mật Đám mây và Tự động hóa:\nKích hoạt và đánh giá điểm tuân thủ sử dụng AWS Security Hub. Tạo các quy trình tự động hóa Serverless sử dụng AWS Lambda và IAM Roles. Quản lý tài nguyên EC2 thông qua các chiến lược gắn thẻ (tagging). Tiến độ Dự án:\nHoàn thành chuỗi bài thực hành mở rộng (Module 05). Hoàn thiện và thống nhất lộ trình chi tiết cho dự án cuối khóa. "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/1-worklog/1.6-week6/","title":"Worklog Tuần 6","tags":[],"description":"","content":"Mục tiêu Tuần 6: Nắm vững các nguyên tắc cơ bản về Bảo mật AWS: Shared Responsibility Model, Identity Center, và Quản lý Khóa (Key Management). Phát triển kỹ năng thiết kế và trực quan hóa Kiến trúc Đám mây sử dụng các tiêu chuẩn chuyên nghiệp (Draw.io). Đi sâu vào các Mô hình NLP Attention: Seq2seq, Dịch máy Nơ-ron (NMT), và các chỉ số Đánh giá. Phối hợp với nhóm để phác thảo và hoàn thiện Kiến trúc Tổng quan (High-Level Architecture) cho dự án cuối khóa. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Học cách vẽ sơ đồ kiến trúc AWS - Làm quen và thực hành vẽ nháp với Draw.io - Làm lab Module05-44 - Làm lab Module05-48 13/10/2025 13/10/2025 https://www.youtube.com/@AWSStudyGroup/ 3 - Tìm hiểu Share Responsibility Model - Tìm hiểu về Amazon Identity \u0026amp; access management - Tìm hiểu về AWS Cognito - Tìm hiểu về AWS Organization - Tìm hiểu về AWS Identity Center - Tìm hiểu về Amazon Key Management Service - Tìm hiểu AWS Security Hub - Nghiên cứu thực hành và bổ sung về những gì đã học trong ngày 14/10/2025 14/10/2025 https://www.youtube.com/@AWSStudyGroup/ 4 - Meeting phác thảo sơ đồ kiến trúc tổng quan lại các dịch vụ sẽ dùng - Tìm hiểu về Seq2seq model - Tìm hiểu Queries, Keys, Values, and Attention - Tìm hiểu về Seq2seq Model with Attention - Tìm hiểu về NMT Model, Machine Translation - Tìm hiểu về BLEU Score \u0026amp; ROUGE-N Score - Tìm hiểu về Beam Search \u0026amp; Minimum Bayes Risk 15/10/2025 15/10/2025 https://www.coursera.org/learn/attention-models-in-nlp/ 5 - Tìm hiểu cấu trúc của sơ đồ kiến trúc AWS - Thực hành vẽ và chỉnh sửa sơ đồ 16/10/2025 16/10/2025 https://www.youtube.com/@AWSStudyGroup/ 6 - Tổng ôn lại kiến thức của tuần - Tiếp tục chỉnh sửa và xin góp ý của các anh chị trong nhóm về sơ đồ kiến trúc của nhóm - Meeting với nhóm để thảo luận về sơ đồ kiến trúc AWS 17/10/2025 17/10/2025 https://www.youtube.com/@AWSStudyGroup/ Thành tựu Tuần 6: Củng cố Kiến thức Bảo mật Đám mây:\nHiểu rõ về Shared Responsibility Model. Cấu hình IAM và AWS Identity Center để quản lý người dùng. Khám phá AWS Cognito cho xác thực ứng dụng và KMS để mã hóa. Thiết kế Kiến trúc Chuyên nghiệp:\nSử dụng thành thạo Draw.io với bộ AWS Icons. Phác thảo Kiến trúc Tổng quan (High-Level Architecture) ban đầu cho dự án cuối khóa. Nhận và triển khai các phản hồi về cấu trúc sơ đồ. Nắm vững các Khái niệm NLP Nâng cao (Attention Models):\nHiểu cơ chế hoạt động của Seq2seq và Attention mechanism (Queries, Keys, Values). Học cách đánh giá các mô hình Dịch máy sử dụng các điểm số BLEU và ROUGE-N. Nắm bắt các kỹ thuật lấy mẫu như Beam Search. Hợp tác Nhóm:\nThống nhất tầm nhìn của nhóm về kiến trúc hệ thống thông qua các cuộc họp có cấu trúc. "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/1-worklog/1.7-week7/","title":"Worklog Tuần 7","tags":[],"description":"","content":"Mục tiêu Tuần 7: Nắm vững các dịch vụ Cơ sở dữ liệu AWS: RDS, Aurora, Redshift, và ElastiCache. Phát triển kỹ năng AI thực tế: Nghiên cứu và triển khai một AI Chatbot. Hoàn thiện Sơ đồ Kiến trúc Tổng quan dựa trên phản hồi của người hướng dẫn. Bắt đầu triển khai Dự án Cuối khóa: Thiết kế Frontend và Backend. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm lab Module06 - Tiếp tục chỉnh sửa Sơ đồ 20/10/2025 20/10/2025 https://www.youtube.com/@AWSStudyGroup/ 3 - Tìm hiểu Database Concepts - Tìm hiểu về Amazon RDS \u0026amp; Amazon Aurora - Tìm hiểu về Redshift - Elasticache - Tìm hiểu cách để tạo chatbot AI 21/10/2025 21/10/2025 https://www.youtube.com/@AWSStudyGroup/ 4 - Thực hành tạo chatbot AI - Nghiên cứu và bổ sung kiến thức AI về chatbot - Chỉnh sửa lại sơ đồ theo review của các anh trên nhóm 22/10/2025 22/10/2025 https://www.youtube.com/ 5 - Tiến hành làm dự án cuối kì - Thiết kế Front-End \u0026amp; Back-end 23/10/2025 23/10/2025 6 - Tổng ôn lại kiến thức của tuần - Tiếp tục chỉnh sửa và xin góp ý của các anh chị trong nhóm về sơ đồ kiến trúc của nhóm - Kiểm thử AI và thiết kế các phần Front-end và Back-end 24/10/2025 24/10/2025 Thành tựu Tuần 7: Hiểu sâu về Hệ sinh thái Cơ sở dữ liệu AWS:\nPhân biệt được giữa các dịch vụ Quan hệ (RDS, Aurora) và Kho dữ liệu (Redshift). Hiểu các chiến lược In-memory caching sử dụng Amazon ElastiCache. Triển khai AI \u0026amp; Machine Learning:\nĐã nghiên cứu và tạo mẫu (prototype) thành công một AI Chatbot hoạt động được. Tích hợp logic AI vào phạm vi dự án. Hoàn thiện Kiến trúc \u0026amp; Thiết kế:\nTinh chỉnh và chốt Sơ đồ Kiến trúc Hệ thống sau nhiều vòng phản hồi/đánh giá. Thực thi Dự án:\nChính thức bắt đầu giai đoạn coding cho Dự án Cuối khóa. Hoàn thành các thiết kế ban đầu cho cả cấu trúc Frontend (UI/UX) và Backend. "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/1-worklog/1.8-week8/","title":"Worklog Tuần 8","tags":[],"description":"","content":"Mục tiêu Tuần 8: Hoàn thiện Kiến trúc Hệ thống và tích hợp mô-đun AI vào dự án chính. Hoàn thành giai đoạn phát triển cốt lõi: Frontend cơ bản, Backend, và Đề xuất Dự án. Ôn tập toàn diện tất cả các mô-đun AWS và kiến thức bổ sung đã học đến nay. Hoàn thành thành công Bài kiểm tra giữa kỳ. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Chỉnh sửa lại sơ đồ kiến trúc và thay đổi 1 số dịch vụ - Hoàn thiện AI và tiến hành tích hợp vào dự án 27/10/2025 27/10/2025 3 - Viết proposal - Meeting cùng làm dự án với các thành viên trong nhóm - Hoàn thành căn bản được Front-end và Back-end 28/10/2025 28/10/2025 4 - Ôn tập lại tất cả những gì đã học được - Ôn tập thêm kiến thức bổ sung 29/10/2025 29/10/2025 https://www.youtube.com/@AWSStudyGroup/ https://cloudjourney.awsstudygroup.com/ 5 - Ôn tập lại tất cả những gì đã học được - Ôn tập thêm kiến thức bổ sung 30/10/2025 30/10/2025 https://www.youtube.com/@AWSStudyGroup/ https://cloudjourney.awsstudygroup.com/ 6 - Thi giữa kì - Meeting chỉnh sửa 1 vài chức năng liên của dự án cuối kì 31/10/2025 31/10/2025 Thành tựu Tuần 8: Tích hợp \u0026amp; Tối ưu hóa Hệ thống:\nĐã tích hợp thành công AI Chatbot/Model vào ứng dụng chính. Đã sửa đổi Sơ đồ Kiến trúc AWS để tối ưu hóa việc lựa chọn dịch vụ dựa trên nhu cầu triển khai thực tế. Các cột mốc Phát triển Dự án:\nHoàn thành cấu trúc cơ bản cho cả Front-end và Back-end. Hoàn thiện và lập tài liệu cho Đề xuất Dự án. Củng cố Kiến thức \u0026amp; Đánh giá:\nThực hiện ôn tập toàn diện các mô-đun của các tuần trước (Tính toán, Lưu trữ, Mạng, Cơ sở dữ liệu, Bảo mật). Hoàn thành Bài kiểm tra giữa kỳ. Thích ứng Agile:\nĐiều chỉnh chức năng dự án dựa trên các cuộc họp nhóm và kết quả kiểm thử. "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/1-worklog/1.9-week9/","title":"Worklog Tuần 9","tags":[],"description":"","content":"Mục tiêu Tuần 9: Đi sâu vào các kiến trúc NLP hiện đại: Transformers, Attention Mechanisms, và Decoders. Khám phá Transfer Learning và các Mô hình Ngôn ngữ Lớn (LLMs) như BERT, GPT, và T5. Triển khai các giải pháp Generative AI sử dụng AWS Bedrock. Tối ưu hóa kiến trúc Dự án Cuối khóa và tinh chỉnh hiệu suất/UI của Chatbot. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu về Transformers vs RNNs - Tìm hiểu về Scaled and Dot-Product Attention - Tìm hiểu về Masked Self Attention - Tìm hiểu về Transformer Decoder 03/11/2025 03/11/2025 https://www.coursera.org/learn/attention-models-in-nlp/ 3 - Làm lab code thực hành về Transformer Summarizer - Tối ưu lại ChatBot và giao diện 04/011/2025 04/11/2025 https://www.coursera.org/learn/attention-models-in-nlp/\u003e 4 - Meeting thay đổi 1 số dịch vụ AWS tối ưu lại dự án - Tìm hiểu Transfer Learning in NLP - Tìm hiểu về các mô hình ngôn ngữ lớn ELMo, GPT, BERT, T5 05/11/2025 05/11/2025 https://www.coursera.org/learn/attention-models-in-nlp/ 5 - Tìm hiểu về AWS Bedrock - Thử nghiệm tại AI Chatbot với AWS Bedrock 06/11/2025 06/11/2025 6 - Tìm kiếm và tạo dữ liệu cho Chatbot tạo bằng AWS Bedrock - Kiểm thử ChatBot và sửa 1 vài lỗi liên quan đến quá trình làm 07/11/2025 07/11/2025 Thành tựu Tuần 9: Nắm vững các Kiến trúc NLP Nâng cao:\nPhân biệt giữa RNNs và Transformers. Hiểu các cơ chế cốt lõi: Scaled Dot-Product Attention và Masked Self-Attention. Triển khai một Transformer Summarizer thông qua các bài thực hành code. Hiểu về các Mô hình Ngôn ngữ Lớn (LLMs):\nCó cái nhìn sâu sắc về các chiến lược Transfer Learning. Khám phá sự phát triển của các mô hình lớn: ELMo, GPT, BERT, và T5. Ứng dụng Generative AI với AWS:\nTích hợp thành công AWS Bedrock để nâng cấp khả năng của AI Chatbot. Chọn lọc tập dữ liệu cho fine-tuning/context và giải quyết các lỗi tích hợp. Tối ưu hóa Dự án:\nTinh chỉnh Giao diện người dùng (UI) để có trải nghiệm người dùng tốt hơn. Đánh giá lại và tối ưu hóa bộ dịch vụ AWS cho sản phẩm cuối cùng. "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/4-eventparticipated/4.3-event3/","title":"Sự kiện 3","tags":[],"description":"","content":"Báo cáo tổng hợp: “AWS AI/ML và Generative AI Workshop” Mục tiêu sự kiện Nắm bắt tổng quan các dịch vụ AWS AI/ML (Amazon SageMaker) và nền tảng AI sinh tạo (Amazon Bedrock). Hiểu sâu về phương pháp luận AIDLC (AI-Driven Development) để tăng tốc độ phát triển phần mềm. Làm chủ công cụ Kiro IDE và các khái niệm mới như Spec-Driven Development (SDD) và Agent Hooks. Học cách tư duy Prompt Engineering hiệu quả và quản lý ngữ cảnh để làm việc với AI. Điểm nổi bật chính Dịch vụ AWS AI/ML và Bedrock Chương trình đã giới thiệu bức tranh toàn cảnh về khả năng AI của AWS:\nAmazon SageMaker: Nền tảng ML end-to-end bao gồm chuẩn bị dữ liệu, huấn luyện, tinh chỉnh và MLOps tích hợp. Amazon Bedrock: Dịch vụ chủ đạo cho AI Sinh tạo, cho phép lựa chọn các Foundation Models (Claude, Llama, Titan). Các tính năng nâng cao: Thảo luận về kiến trúc RAG (Retrieval-Augmented Generation), tích hợp Knowledge Base, Bedrock Agents cho quy trình đa bước và Guardrails để lọc nội dung. Phương pháp luận AIDLC (AI-Driven Development) Đây là trọng tâm của sự thay đổi cách làm việc, giúp rút ngắn thời gian từ 2 tuần xuống 1.5 ngày:\nTriết lý Human-Centric: Con người nắm vai trò xác nhận (validation) và ra quyết định. AI không bao giờ tự động quyết định thay con người. Quy trình 3 giai đoạn: Inception (Định hình yêu cầu/User Story), Construction (Triển khai Unit), và Operation (Deploy/CICD). Phát triển theo nhóm (Mob Development): Đề xuất mô hình làm việc nhóm đa vai trò (BA, Engineer, SA, QA) trên cùng một máy để xác nhận đầu ra ngay lập tức. Công cụ Kiro IDE \u0026amp; Spec-Driven Development Khám phá IDE thế hệ mới tích hợp sâu AI (tương tự Coder/VS Code):\nSpec-Driven Development (SDD): Bắt đầu bằng tài liệu đặc tả (spec) thay vì viết code. Kiro tự động tạo các file requirement, design, và task list. Agent Hooks: Tính năng tự động hóa tác vụ dựa trên sự kiện bằng ngôn ngữ tự nhiên (ví dụ: tự chạy test khi lưu file). Advanced Context Management: Tự động chạy quy trình AIDLC thông qua file cấu hình steering. Quản lý ngữ cảnh (Context Management) Tối ưu hóa đầu vào: AI hiểu ngữ cảnh ngôn ngữ tốt hơn code thô. Cần rút trích code thành project summary hoặc mô hình miền (domain model). Kiểm soát Session: Tạo session riêng cho từng tác vụ (Unit of Work) để tránh \u0026ldquo;ngộ độc ngữ cảnh\u0026rdquo; (context overload) và giảm thiểu ảo giác (hallucination). Bài học chính Tư duy làm việc với AI Lập kế hoạch là bắt buộc: Khi yêu cầu AI làm việc, bắt buộc phải yêu cầu nó tạo Plan trước. Lặp lại việc tạo Plan cho đến khi chính xác mới tiến hành. Tư duy \u0026ldquo;Đừng cấm đoán\u0026rdquo;: Thay vì bảo AI \u0026ldquo;đừng làm X\u0026rdquo;, hãy hướng dẫn cụ thể \u0026ldquo;hãy làm Y\u0026rdquo;. Các câu lệnh phủ định thường kém hiệu quả hơn khẳng định. Vai trò mới của Developer: Chuyển dịch từ người viết code (coding) sang người giám sát (oversight), xác thực (validation) và ra quyết định. Kỹ thuật Prompting Xác định Persona: Luôn định nghĩa vai trò rõ ràng cho AI ngay từ đầu. Input/Output rõ ràng: Chỉ định định dạng đầu ra cụ thể (ví dụ: file Markdown) thay vì để AI lưu trong bộ nhớ tạm. Áp dụng vào công việc Áp dụng quy trình AIDLC: Bắt đầu chia nhỏ dự án thành các giai đoạn Inception, Construction, Operation và thực hành tạo Plan trước khi code. Chuyển đổi công cụ IDE: Thử nghiệm Kiro IDE hoặc các công cụ hỗ trợ AI tương tự, tận dụng Agent Hooks để tự động hóa quy trình kiểm thử. Tối ưu hóa Context: Xây dựng th অভ্যাস viết tài liệu tóm tắt kiến trúc và domain model để nạp context cho AI thay vì quăng toàn bộ source code. Thực hành Mob Development: Tổ chức các phiên làm việc nhóm tập trung để validate kết quả do AI tạo ra ngay lập tức. Trải nghiệm sự kiện Tham dự Workshop \u0026ldquo;AWS AI/ML và Generative AI\u0026rdquo; đã mang lại một góc nhìn hoàn toàn mới về tương lai của lập trình. Những trải nghiệm đáng nhớ bao gồm:\nSự thay đổi về tốc độ và tư duy em thực sự ấn tượng với khái niệm AIDLC, đặc biệt là khả năng rút ngắn thời gian phát triển đáng kinh ngạc. Nó không chỉ là công cụ nhanh hơn, mà là cách tiếp cận vấn đề hoàn toàn khác. Hình tượng \u0026ldquo;Chiếc xe tự lái\u0026rdquo; Ví dụ minh họa về việc phát triển phần mềm giống như điều khiển xe tự lái thực sự sâu sắc. em nhận ra mình không cần lái từng mét đường, nhưng phải là người cầm bản đồ (Plan) và chịu trách nhiệm đạp phanh (Validation) để đảm bảo an toàn. Sức mạnh của Amazon Bedrock Phần demo về Bedrock Agents và RAG cho thấy tiềm năng to lớn trong việc xây dựng các ứng dụng thông minh có khả năng suy luận và truy xuất dữ liệu doanh nghiệp, chứ không chỉ là chat bot đơn thuần. Tiếp cận Kiro IDE Việc tìm hiểu về Spec-Driven Development (SDD) trong Kiro dù được đánh giá là hơi cứng nhắc cho dự án lớn, nhưng lại mở ra hướng đi tuyệt vời cho việc prototyping nhanh chóng và giảm thiểu lỗi sai ngay từ khâu thiết kế. "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":"ReGenZ Electric Vehicle Service Platform Nền tảng quản lí và bảo dưỡng OTO điện ReGenZ 1. Tóm tắt điều hành ReGenZ là một nền tảng quản lý toàn diện, được thiết kế nhằm số hóa và tối ưu hóa quy trình bảo dưỡng tại các trung tâm dịch vụ. Hệ thống quản lý tập trung toàn bộ vòng đời dịch vụ—từ tiếp nhận yêu cầu, xử lý sửa chữa đến chăm sóc khách hàng—giúp loại bỏ thao tác thủ công và nâng cao hiệu quả. Tận dụng sức mạnh đám mây AWS, ReGenZ kết hợp kiến trúc container linh hoạt trên Amazon ECS Fargate với khả năng xử lý thông minh của Generative AI thông qua Amazon Bedrock. Giải pháp tích hợp quy trình phát triển tự động (CI/CD) từ GitLab, đảm bảo tốc độ triển khai nhanh chóng, bảo mật cao và khả năng giám sát chặt chẽ, mang lại trải nghiệm vượt trội cho người dùng cuối.\n2. Tuyên bố vấn đề Vấn đề hiện tại\nQuy trình vận hành hiện tại còn phụ thuộc nhiều vào các phương pháp thủ công, dẫn đến hiệu suất làm việc không hiệu quả, dữ liệu rời rạc và thiếu các công cụ hỗ trợ thông minh để tương tác với khách hàng một cách tự động. Giải pháp\nNền tảng sử dụng kiến trúc hiện đại, bắt đầu từ lớp Edge với Amazon Route 53 để điều hướng người dùng. Giao diện (Frontend) được lưu trữ trên AWS Amplify Hosting, đảm bảo khả năng truy cập nhanh chóng và ổn định.\nAmazon API Gateway đóng vai trò là cổng trung tâm, phân luồng yêu cầu một cách thông minh:\nĐể đảm bảo an ninh, các thành phần quan trọng như ECS Fargate và cơ sở dữ liệu Amazon RDS được đặt trong Private Subnet (Mạng riêng), hoàn toàn tách biệt với internet công cộng. Dữ liệu hình ảnh được lưu trữ trên Amazon S3 và truy cập an toàn qua S3 Endpoints. Ngoài ra, quy trình phát triển phần mềm được tự động hóa hoàn toàn: mã nguồn từ GitLab được đóng gói và đẩy vào Amazon ECR để triển khai lên ECS.\nLợi ích và hoàn vốn đầu tư (ROI)\nViệc áp dụng kiến trúc này mang lại lợi thế cạnh tranh lớn nhờ tích hợp Trí tuệ nhân tạo (GenAI) qua Amazon Bedrock, giúp tự động hóa việc chăm sóc khách hàng và phân tích dữ liệu. Hệ thống đảm bảo tính sẵn sàng cao và an toàn dữ liệu nhờ thiết kế VPC phân tách mạng (Public/Private subnets).\nQuy trình CI/CD tích hợp với GitLab và ECR giúp giảm thiểu thời gian chết khi cập nhật tính năng mới, trong khi Amazon CloudWatch cung cấp khả năng giám sát toàn diện để phát hiện sự cố tức thì. Mô hình chi phí tối ưu nhờ sử dụng Fargate (Serverless container) và Lambda (Pay-per-use) giúp doanh nghiệp chỉ trả tiền cho tài nguyên thực dùng. Khoản đầu tư này không chỉ giải quyết bài toán vận hành hiện tại mà còn tạo nền tảng công nghệ vững chắc cho sự tăng trưởng dài hạn với thời gian hoàn vốn (ROI) dự kiến được rút ngắn đáng kể.\n3. Kiến trúc giải pháp Nền tảng quản lý ReGenZ áp dụng kiến trúc hiện đại được triển khai trên AWS (Region ap-southeast-2), bắt đầu với việc người dùng truy cập thông qua Amazon Route 53 tại lớp biên (Edge layer). Giao diện người dùng (Frontend) được lưu trữ trên AWS Amplify Hosting, thiết lập kết nối trực tiếp đến Amazon API Gateway - đóng vai trò là cổng giao tiếp trung tâm.\nTừ API Gateway, luồng dữ liệu được phân chia một cách chiến lược thành ba nhánh riêng biệt:\nTác vụ AI (AI Tasks): Các yêu cầu được định tuyến đến AWS Lambda để tương tác với Amazon Bedrock nhằm thực hiện các tính năng AI tạo sinh. Tác vụ Thông báo (Notification Tasks): Các yêu cầu bất đồng bộ sẽ kích hoạt AWS Lambda để xử lý việc gửi email thông qua Amazon SES. Logic Nghiệp vụ Cốt lõi (Core Business Logic): Lưu lượng truy cập được điều hướng qua Application Load Balancer (ALB) đặt tại Public Subnet, sau đó chuyển tiếp đến các tác vụ Amazon ECS Fargate được bảo vệ an toàn bên trong Private Subnet. Dữ liệu \u0026amp; Bảo mật:\nDữ liệu quan hệ được lưu trữ bền vững trong Amazon RDS thuộc Private Subnet. Để tối ưu hóa bảo mật và hiệu năng, kiến trúc sử dụng VPC Endpoints để giữ lưu lượng mạng hoàn toàn bên trong mạng nội bộ của AWS:\nTài nguyên tĩnh và hình ảnh lưu trên Amazon S3 được truy cập an toàn thông qua S3 Endpoints. Các image container được kéo trực tiếp từ Amazon ECR thông qua ECR Endpoints. Bằng việc tận dụng các Endpoint này, hệ thống loại bỏ sự cần thiết của NAT Gateway, qua đó giúp giảm chi phí hạ tầng và hạn chế tối đa việc tiếp xúc với internet công cộng.\nDevOps \u0026amp; Giám sát:\nGitLab được sử dụng để quản lý mã nguồn và quy trình CI/CD, tự động đẩy các bản triển khai lên Amplify (cho Frontend) và các image lên ECR (cho Backend). Amazon CloudWatch đảm bảo việc giám sát hệ thống toàn diện và ghi log (logging) cho tất cả các dịch vụ. Dịch vụ AWS sử dụng\nRoute 53: Dịch vụ DNS, chịu trách nhiệm định tuyến tên miền (Edge layer) đến ứng dụng. AWS Amplify Hosting: Lưu trữ giao diện web (frontend) và có thể tích hợp với CDN/WAF. Trong sơ đồ, nó nhận traffic từ Route 53. Amazon API Gateway: Cổng vào chính (Gateway), tiếp nhận và điều hướng toàn bộ yêu cầu từ frontend/Amplify đến các dịch vụ xử lý. AWS Lambda (Bedrock): Xử lý các tác vụ liên quan đến AI/Generative AI (dự đoán/tạo nội dung) bằng cách giao tiếp với Amazon Bedrock. AWS Lambda (SES): Xử lý các tác vụ bất đồng bộ, ví dụ như xử lý thông báo để gửi email thông qua AWS SES. Amazon Bedrock: Dịch vụ AI tổng quát (Gen AI), cung cấp các mô hình nền tảng để thực hiện các nghiệp vụ thông minh. AWS SES: Dịch vụ gửi email, thực hiện việc gửi các thông báo, báo giá hoặc kết quả xử lý từ Lambda. VPC: Môi trường mạng ảo, nơi chứa và bảo vệ các tài nguyên AWS (như ALB, ECS Fargate, RDS). ALB (Application Load Balancer): Bộ cân bằng tải, phân phối lưu lượng truy cập từ API Gateway đến các container ứng dụng chạy trên ECS Fargate. Amazon ECS Fargate: Chạy ứng dụng backend dưới dạng container mà không cần quản lý máy chủ, xử lý các logic nghiệp vụ chính. Amazon RDS: Cung cấp cơ sở dữ liệu quan hệ, được đặt trong Private Subnet để lưu trữ dữ liệu có cấu trúc. Amazon S3: Lưu trữ các tệp đa phương tiện như ảnh hoặc các dữ liệu lớn khác. ECR: Kho lưu trữ các image container (Docker) của ứng dụng, được dùng bởi ECS Fargate để triển khai. AWS CloudWatch: Dịch vụ giám sát, thu thập log và metrics từ toàn bộ hệ thống để theo dõi hiệu suất và phát hiện sự cố. Thiết kế Thành phần Xử lý Yêu cầu (Request Handling): Amazon Route 53 điều hướng tên miền người dùng đến AWS Amplify Hosting, nơi lưu trữ giao diện web (Frontend). Các yêu cầu từ giao diện sau đó được chuyển tiếp đến Amazon API Gateway, đóng vai trò là cổng trung tâm tiếp nhận và định tuyến mọi lưu lượng truy cập.\nXử lý Logic Nghiệp vụ (Business Logic Processing):\nLogic Cốt lõi: Mọi nghiệp vụ chính được xử lý bởi các ứng dụng chạy trên Amazon ECS Fargate, đặt trong mạng riêng (Private Subnet) để đảm bảo an ninh. Tác vụ AI/Bất đồng bộ: Các tác vụ AI tạo sinh được xử lý bởi AWS Lambda kết nối với Amazon Bedrock. Các tác vụ phụ trợ như gửi email được xử lý bởi AWS Lambda kích hoạt Amazon SES. Hạ tầng Mạng (Network Infrastructure):\nPublic Subnet: Chứa các dịch vụ cần tiếp xúc với bên ngoài, cụ thể là Application Load Balancer (ALB). Private Subnet: Chứa các tài nguyên nhạy cảm như ECS Fargate và Amazon RDS, cách ly chúng khỏi truy cập trực tiếp từ công chúng. VPC Endpoints: Hệ thống sử dụng S3 Endpoints và ECR Endpoints, cho phép ECS Fargate giao tiếp an toàn với Amazon S3 và ECR ngay trong mạng nội bộ AWS mà không cần đi qua internet công cộng. Lưu trữ Dữ liệu (Data Storage):\nAmazon RDS: Lưu trữ dữ liệu có cấu trúc và dữ liệu nhạy cảm. Amazon S3: Lưu trữ các tập tin đa phương tiện và dữ liệu lớn. Triển khai và Giám sát (Deployment and Monitoring): Quy trình triển khai được quản lý qua GitLab, tự động kích hoạt cập nhật cho AWS Amplify (Frontend) và đẩy Docker image lên Amazon ECR (Backend). Amazon CloudWatch thực hiện giám sát tổng thể hiệu năng, log và các chỉ số (metrics) cho tất cả dịch vụ từ ECS, Lambda đến RDS.\n4. Triển khai Kỹ thuật (Technical Implementation) Các Giai đoạn Thực hiện\nDự án phát triển Nền tảng bảo dưỡng xe điện thông minh ReGenZ — bao gồm việc tích hợp trợ lý ảo AI và hệ thống quản lý dịch vụ — trải qua 4 giai đoạn:\nNghiên cứu và Thiết kế Kiến trúc: Tìm hiểu các công nghệ phù hợp (React.js, Spring Boot, AWS Bedrock) và thiết kế kiến trúc hệ thống kết hợp giữa Containers (ECS) và Serverless (Lambda) trên nền tảng AWS (1 tháng trước khi bắt đầu). Ước tính Chi phí và Kiểm tra Tính khả thi: Sử dụng AWS Pricing Calculator để ước tính chi phí vận hành cho các dịch vụ cốt lõi như ECS Fargate, RDS và chi phí token cho Amazon Bedrock, từ đó đề xuất giải pháp khả thi nhất. Điều chỉnh Kiến trúc để Tối ưu hóa: Tinh chỉnh kiến trúc, lựa chọn cấu hình phù hợp cho ECS Fargate và RDS, đồng thời tối ưu hóa thời gian chạy (runtime) của Lambda để cân bằng giữa hiệu suất xử lý AI và chi phí. Phát triển, Kiểm thử và Triển khai: Lập trình ứng dụng React.js (Frontend) và Spring Boot (Backend), tích hợp Bedrock Agent, triển khai quy trình CI/CD qua GitLab, đóng gói Docker image lên ECR và vận hành trên ECS. Yêu cầu Kỹ thuật\nGiao diện Người dùng (Frontend): Yêu cầu kiến thức thực tế về React.js để xây dựng giao diện đặt lịch và tính năng chat với trợ lý ảo AI. Sử dụng AWS Amplify để tự động hóa quy trình triển khai (Hosting), kết nối với Amazon API Gateway để gửi các yêu cầu xử lý bảo mật, đảm bảo trải nghiệm mượt mà trên mọi thiết bị.\nHệ thống Cốt lõi (Backend \u0026amp; Infrastructure): Yêu cầu kiến thức chuyên sâu về Java/Spring Boot để phát triển logic nghiệp vụ bảo dưỡng. Ứng dụng được đóng gói bằng Docker, với các image được lưu trữ trên Amazon ECR và chạy trên Amazon ECS Fargate. Cần có sự hiểu biết về Amazon RDS cho cơ sở dữ liệu quan hệ (lưu trữ hồ sơ xe, lịch sử bảo dưỡng). Đặc biệt, yêu cầu kỹ năng lập trình AWS Lambda (Python) để kết nối với Amazon Bedrock (xử lý AI/Chatbot) và AWS SES (gửi thông báo email bất đồng bộ). Việc giám sát hệ thống được thực hiện thông qua tích hợp Amazon CloudWatch.\n5. Mốc thời gian \u0026amp; Kế hoạch thực hiện Kế hoạch Dự án\nGiai đoạn 1 (Tuần 1-2): Thiết kế và Xây dựng nền tảng:\nPhân tích \u0026amp; Thiết kế: Thiết kế chi tiết kiến trúc AWS (VPC, Subnets, Security Groups), thiết kế Cơ sở dữ liệu (RDS Schema) và định nghĩa API (Swagger/OpenAPI). Thiết lập Hạ tầng: Cấu hình VPC (Public/Private Subnets) và các IAM Roles cần thiết. Thiết lập CI/CD: Cấu hình Pipeline trên GitLab để tự động build Docker Image, đẩy lên Amazon ECR và triển khai Frontend lên AWS Amplify. Giai đoạn 2 (Tuần 3-4): Phát triển Luồng Dịch vụ Cốt lõi:\nLuồng Khách hàng: Phát triển Đăng ký/Đăng nhập, Quản lý hồ sơ xe, Đặt lịch hẹn (dữ liệu lưu trong RDS). Luồng Cố vấn Dịch vụ: Xây dựng tính năng Tiếp nhận xe, Tạo báo giá và Lệnh sửa chữa. Luồng Kỹ thuật viên: Xem danh sách công việc (Task list), Cập nhật tiến độ bảo dưỡng và tải ảnh/video lên Amazon S3. Giai đoạn 3 (Tuần 5-6): Quản trị \u0026amp; Tính năng Nâng cao:\nModule Quản trị: Xây dựng Dashboard báo cáo, Quản lý phụ tùng (Kho) và Quản lý nhân sự. Tích hợp AI: Viết AWS Lambda kết nối với Amazon Bedrock Agent (Chatbot hỗ trợ khách hàng) và tích hợp qua API Gateway. Hệ thống Thông báo: Viết AWS Lambda kích hoạt AWS SES để gửi email tự động/báo giá cho khách hàng. Bảo mật Mạng: Cấu hình VPC Endpoints (S3, ECR) để đảm bảo kết nối riêng tư, an toàn giữa các tài nguyên trong Private Subnet và các dịch vụ AWS mà không cần ra internet. Giai đoạn 4 (Tuần 7-8): Kiểm thử, Tối ưu và Vận hành:\nKiểm thử Chấp nhận (UAT): Kiểm thử nội bộ để đảm bảo luồng dữ liệu từ Web -\u0026gt; API Gateway -\u0026gt; Lambda/ECS -\u0026gt; DB hoạt động trơn tru. Tối ưu Bảo mật: Cấu hình AWS WAF (chặn SQL Injection, XSS) và rà soát quyền truy cập IAM. Giám sát Vận hành: Thiết lập Dashboard trên Amazon CloudWatch để theo dõi log và chỉ số (metrics) của ECS Fargate và Lambda. Triển khai Chính thức. 6. Ước tính ngân sách Chi phí hạ tầng\nAmazon ECS Fargate: ~11,00 USD/tháng. Application Load Balancer (ALB): ~16,43 USD/tháng. Amazon Bedrock (AI): ~5,00 USD/tháng (Tính theo số lượng Token) AWS Lambda: 0,00 USD/tháng (Free Tier) Amazon RDS \u0026amp; ElastiCache: 0,00 USD/tháng (Free Tier) S3 Standard: ~0,15 USD/tháng. AWS Amplify \u0026amp; API Gateway: ~0,50 USD/tháng. Amazon CloudWatch: 0,00 USD/tháng (Free Tier) Amazon SES: 0,00 USD/tháng (Free Tier) Tổng: ~32,63/tháng.\n7. Đánh giá Rủi ro (Risk Assessment) Ma trận Rủi ro Ngừng hoạt động hệ thống (Downtime): Tác động Cao, Xác suất Thấp. Vi phạm bảo mật / Mất dữ liệu: Tác động Rất cao, Xác suất Thấp. Vượt ngân sách vận hành: Tác động Trung bình, Xác suất Trung bình. AI phản hồi sai lệch (Hallucination): Tác động Trung bình, Xác suất Trung bình. Chiến lược Giảm thiểu (Mitigation Strategies) Ổn định Hệ thống: Triển khai hạ tầng trên đa vùng sẵn sàng (Multi-AZ) cho RDS và ECS Fargate. Sử dụng Application Load Balancer (ALB) để phân phối tải tự động và kiểm tra trạng thái dịch vụ. Bảo mật: Các tài nguyên Backend (ECS, RDS) được đặt trong Private Subnet, hoàn toàn cách ly khỏi internet công cộng. Việc truy cập vào Amazon S3 và ECR được bảo mật thông qua các VPC Endpoints nội bộ, đảm bảo dữ liệu không đi ra ngoài mạng AWS. Áp dụng chặt chẽ các IAM Role cho AWS Lambda và ECS Tasks theo nguyên tắc đặc quyền tối thiểu (least privilege). Quản lý Chi phí: Sử dụng AWS Budgets để thiết lập cảnh báo khi chi phí vượt quá ngưỡng. Thường xuyên giám sát và tối ưu hóa tài nguyên để tránh lãng phí. Kiểm soát chất lượng AI: Giới hạn phạm vi phản hồi của Amazon Bedrock Agent thông qua Prompt Engineering chặt chẽ (System Prompts) và chỉ cho phép trích xuất thông tin từ các Cơ sở kiến thức (Knowledge Bases) đã được kiểm duyệt. Kế hoạch Dự phòng (Contingency Plans) Phục hồi Dữ liệu: Kích hoạt tính năng Automated Backups cho Amazon RDS và sử dụng Point-in-Time Recovery để khôi phục dữ liệu về bất kỳ thời điểm nào trong trường hợp xảy ra lỗi. Khả năng mở rộng: Cấu hình Auto-scaling cho ECS Fargate để tự động mở rộng số lượng Task khi lưu lượng truy cập tăng đột biến, ngăn chặn tình trạng quá tải. 8. Kết quả kỳ vọng Cải tiến kỹ thuật: Xây dựng thành công hệ thống Hybrid Architecture hiện đại kết hợp giữa Microservices (ECS Fargate) và Serverless (Lambda, Bedrock), đảm bảo khả năng mở rộng linh hoạt mà không cần quản lý máy chủ vật lý.\nGiá trị dài hạn:\nNâng cao trải nghiệm khách hàng: Trợ lý ảo AI hoạt động 24/7 giúp giảm thời gian chờ đợi, tăng tỷ lệ chuyển đổi đặt lịch và sự hài lòng của chủ xe. Tài sản dữ liệu: Dữ liệu lịch sử bảo dưỡng và hành vi tương tác được lưu trữ tập trung trên RDS/S3, tạo tiền đề cho việc triển khai các mô hình AI dự đoán bảo trì (Predictive Maintenance) cho pin và động cơ xe điện trong tương lai. "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/5-workshop/5.2-project-architecture/","title":"Kiến trúc Dự án","tags":[],"description":"","content":"Tổng quan Kiến trúc Tài liệu này mô tả kiến trúc sản xuất đề xuất cho ReGenZet — hệ thống quản lý gara xe điện — và giải thích các lựa chọn công nghệ được sử dụng trong workshop.\nFrontend: Ứng dụng React SPA được triển khai và host trên AWS Amplify (CI/CD tự động, hosting tài nguyên và tích hợp CloudFront để cache toàn cầu và phân phối nhanh). Backend: Dịch vụ Spring Boot đóng gói dưới dạng Docker image và chạy trên Amazon ECS (Fargate). Fargate loại bỏ gánh nặng quản lý host và cung cấp compute serverless có khả năng scale cho microservices. Cơ sở dữ liệu: Amazon RDS (MySQL/Postgres) đặt trong private subnets. RDS cung cấp backup tự động, snapshot, tùy chọn Multi-AZ và mã hóa khi lưu (KMS). Quản lý API: Amazon API Gateway làm điểm vào HTTPS duy nhất cho traffic client, xử lý routing, TLS termination và throttling. Lưu trữ media: Amazon S3 lưu ảnh/ video kiểm tra xe và các media khác. Sử dụng presigned URLs để upload/download trực tiếp an toàn, giảm tải cho backend. Thành phần bất đồng bộ / Serverless: Pipeline email: Backend (Spring) publish event đến SNS, kích hoạt Lambda gửi email qua Amazon SES. Pipeline AI/Chat: Frontend → API Gateway → Lambda → Amazon Bedrock (hoặc LLM quản lý khác) cho inference và workflow hội thoại. Mạng \u0026amp; Bảo mật: Triển khai tài nguyên trong VPC với Public/Private subnets rõ ràng. Dùng Security Groups và NACLs để kiểm soát lưu lượng. Dùng VPC Endpoints (Gateway \u0026amp; Interface) cho S3 và truy cập dịch vụ riêng tư, giữ traffic bên trong mạng AWS. Tại sao chọn kiến trúc này? An ninh là ưu tiên\nBackend và RDS nằm trong private subnet và không mở port database ra Internet công cộng. API Gateway và frontend có load balancer terminate TLS ở edge, trong khi các dịch vụ nội bộ giao tiếp qua mạng riêng. Tối ưu chi phí\nFargate và Lambda cung cấp mô hình trả theo sử dụng. Khi phù hợp, cân nhắc Fargate Spot cho workloads không quan trọng và thiết lập autoscaling cùng lifecycle policies cho S3 để giảm chi phí. Đơn giản vận hành \u0026amp; mô hình hiện đại\nTách biệt rõ frontend/backend với API Gateway làm ingress duy nhất. Thành phần event-driven (SNS, Lambda) tách rời xử lý email/AI khỏi luồng request-response, cải thiện tính chịu lỗi và khả năng scale. Nâng cao năng suất phát triển\nAWS Amplify đơn giản hóa CI/CD và hosting frontend. Quy trình container với Docker + ECR và ECS Fargate cho phép deploy lặp lại và dễ tái hiện cho backend. Các điểm bảo mật \u0026amp; best-practice\nIAM theo nguyên tắc least-privilege cho các service và cross-account khi cần. Mã hóa do KMS quản lý cho RDS và đối tượng S3. Sử dụng WAF và rate-limiting trên API Gateway để giảm thiểu các cuộc tấn công ứng dụng. Kiến trúc này cân bằng giữa bảo mật cấp doanh nghiệp và mô hình serverless tối ưu chi phí, đồng thời cung cấp lộ trình thực tế để áp dụng dần các tính năng nâng cao (observability, DR đa vùng, AI dựa trên Bedrock).\n"},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/5-workshop/5.4-databaseandstorage/5.4.2-create-s3/","title":"Tạo AWS S3","tags":[],"description":"","content":"Trong phần này bạn sẽ tạo S3 bucket để lưu trữ ảnh\nMở Amazon S3 Nhấp Create bucket Trong màn hình tạo, nhập tên bucket Để mọi thiết lập mặc định như hình Nhấp Create bucket ở cuối trang "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/5-workshop/5.3-vpc/5.3.3-create-security-groups/","title":"Tạo Security Groups","tags":[],"description":"","content":" Mở Amazon VPC console Chọn Security Groups -\u0026gt; click Create security group Trong Create Security group: Đặt tên cho Security group Chọn VPC đã tạo Thêm rule Inbound và Outbound cho Security Group Trong dự án ReGenZet chúng ta có 4 Security Groups: fargate-sg, rds-sg, alb-sg và endpoint-sg. fargate-sg — security group cho AWS ECS Fargate Lặp lại các bước 1 -\u0026gt; 3 Chọn fargate-sg đã tạo Inbound: thêm rule cho security group của Application Load Balancer (alb-sg) Outbound: thêm rule tới MySQL (rds-sg) và HTTPS Click Create security group rds-sg — security group cho AWS RDS Lặp lại các bước 1 -\u0026gt; 3 Chọn rds-sg đã tạo Inbound: thêm rule cho MySQL theo hướng dẫn Outbound: không cần thêm rule Click Create security group alb-sg — security group cho Application Load Balancer (ALB) Lặp lại các bước 1 -\u0026gt; 3 Inbound: thêm rule HTTPS và HTTP theo hướng dẫn Outbound: thêm rule tới security group của ECS Fargate (fargate-sg) Click Create security group endpoint-sg — security group cho VPC Endpoints Lặp lại các bước 1 -\u0026gt; 3 Inbound: thêm rule cho security group của ECS Fargate (fargate-sg) Outbound: không cần thêm rule "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/5-workshop/5.3-vpc/5.3.2-create-subnets/","title":"Tạo Subnet","tags":[],"description":"","content":"Tạo Public Subnet Mở Amazon VPC console Chọn Subnets -\u0026gt; click Create subnet Trong form Create subnet: Chọn VPC đã tạo Điền tên subnet Chọn Availability Zone Nhập CIDR IPv4 cho subnet Click Create subnet Tạo Private Subnet Lặp lại các bước 1 -\u0026gt; 3 phía trên Chọn Subnet vừa tạo -\u0026gt; Chọn Route table Chọn Route table tương ứng với private Click Save "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/5-workshop/5.3-vpc/5.3.4-create-vpc-endpoints/","title":"Tạo VPC Endpoints","tags":[],"description":"","content":" Mở Amazon VPC console Chọn Endpoints -\u0026gt; nhấp Create endpoints Trong màn hình Create: Điền tên cho VPC endpoint Chọn Type là AWS Services Tìm kiếm dịch vụ cần thiết Trong dự án này chúng ta tạo 5 VPC Endpoints VPC Endpoint S3 Gateway (apexev-s3-gateway) Trong ô tìm kiếm -\u0026gt; com.amazonaws.ap-southeast-1.s3 Chọn type Gateway Chọn VPC đã tạo Chọn Route table private Policy: Full access Nhấp Create endpoint VPC Endpoint ECR API \u0026amp; DKR (Interface) Trong ô tìm kiếm -\u0026gt; ecr Bạn sẽ thấy ecr.api và ecr.dkr (interface) Thực hiện thao tác hai lần, mỗi lần chọn một loại khác nhau Chọn VPC đã tạo Chọn hai subnet private ở hai AZ khác nhau Chọn endpoint-sg Nhấp Create endpoint VPC Endpoint Logs Trong ô tìm kiếm -\u0026gt; com.amazonaws.ap-southeast-1.logs Chọn com.amazonaws.ap-southeast-1.logs Chọn VPC đã tạo Chọn hai subnet private ở hai AZ khác nhau Chọn endpoint-sg Nhấp Create endpoint VPC Endpoint AWS SNS Trong ô tìm kiếm -\u0026gt; com.amazonaws.ap-southeast-1.sns Chọn com.amazonaws.ap-southeast-1.sns Chọn VPC đã tạo Chọn hai subnet private ở hai AZ khác nhau Chọn endpoint-sg Nhấp Create endpoint "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/1-worklog/1.10-week10/","title":"Worklog Tuần 10","tags":[],"description":"","content":"Mục tiêu Tuần 10: Nắm vững các kỹ thuật NLP nâng cao: Kiến trúc BERT, Fine-tuning, và các chiến lược Multi-Task Training. Hoàn thiện giao diện sản phẩm (UI) và thực hiện kiểm thử hệ thống toàn diện. Tối ưu hóa kiến trúc hệ thống bằng cách chuyển đổi tích hợp AI sang mô hình Serverless. Triển khai tích hợp trực tiếp Frontend-to-Bedrock sử dụng AWS Lambda. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Học về Bidirectional Encoder Representations from Transformers - Cách fine tune lại mô hình BERT - Tìm hiểu về Multi-Task Training Strategy - Làm lab code về fine tune lại model BERT dựa trên dữ liệu có sẵn 10/11/2025 10/11/2025 https://www.coursera.org/learn/attention-models-in-nlp/ 3 - Hoàn thiện giao diện người dùng - Các chức năng cơ bản - Tiến hành kiêmr thử sản phẩm 11/01/2025 11/01/2025 4 - Meeting thảo luận về 1 số tính năng sẽ thêm vào - Tối ưu lại hệ thống 12/11/2025 12/11/2025 5 - Tối ưu hệ thống - Sửa lỗi tích hợp liên quan để Bedrock AI ChatBot 13/11/2025 13/11/2025 https://cloudjourney.awsstudygroup.com/ 6 - Viết Lambda Function để tích hợp Bedrock vào Front-end thay vì Back-end - Nghiên cứu cách tích hợp Bedrock vào Front-end của dự án 14/08/2025 14/08/2025 https://cloudjourney.awsstudygroup.com/ Thành tựu Tuần 10: Nắm vững NLP Nâng cao (BERT):\nHiểu kiến trúc Bidirectional Encoder Representations from Transformers (BERT). Áp dụng thành công Multi-Task Training Strategies. Hoàn thành bài thực hành về Fine-tuning BERT với các tập dữ liệu tùy chỉnh để cải thiện độ chính xác của mô hình. Hoàn thiện Sản phẩm:\nHoàn thành User Interface (UI) và xác minh tất cả các chức năng cốt lõi. Thực hiện giai đoạn kiểm thử đầy đủ để phát hiện và xử lý lỗi (bugs). Tái cấu trúc \u0026amp; Tối ưu hóa Kiến trúc:\nChuyển đổi tích hợp AI Chatbot từ cách tiếp cận backend nguyên khối (monolithic) sang Serverless architecture. Phát triển các AWS Lambda functions để cho phép Frontend giao tiếp trực tiếp với AWS Bedrock, cải thiện độ trễ và khả năng mở rộng. Tối ưu hóa hiệu suất tổng thể của hệ thống dựa trên kết quả thảo luận của nhóm. "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/1-worklog/1.11-week11/","title":"Worklog Tuần 11","tags":[],"description":"","content":"Mục tiêu Tuần 11: Hoàn thành và chính thức hóa tất cả tài liệu dự án (Báo cáo thực tập, Đề xuất, và tài liệu Workshop). Đồng bộ hóa sơ đồ kiến trúc kỹ thuật với giải pháp thực tế đã triển khai. Hoàn tất việc tích hợp tất cả các dịch vụ AWS. Thực hiện triển khai cuối cùng dự án lên AWS Cloud và thực hiện kiểm thử sau triển khai. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Viết báo cáo thực tập - Tiếp tục tối ưu hệ thống 17/11/2025 17/11/2025 3 - Sửa lại kiến trúc sơ đồ cho đúng với những thay đổi trong dự án - Sửa lại proposa và Workshop - Meeting để thảo luận với nhóm về sơ đồ và độ hoàn thiện của dự án 18/01/2025 18/01/2025 4 - Chỉnh sửa và hoàn thiện dự án cuối kì 19/11/2025 19/11/2025 5 - Tích hợp các dịch vụ AWS vào dự án 20/11/2025 20/11/2025 https://cloudjourney.awsstudygroup.com/ 6 - Kiểm tra và rà lại lỗi sau khi đã deloy dự án lên AWS 21/08/2025 21/08/2025 Thành tựu Tuần 11: Hoàn thiện Tài liệu:\nSoạn thảo và tinh chỉnh Báo cáo Thực tập (Internship Report). Cập nhật nội dung Project Proposal và Workshop để phản ánh sản phẩm cuối cùng. Đồng bộ hóa Kiến trúc:\nSửa đổi System Architecture Diagram để đảm bảo chính xác 100% với các dịch vụ đã triển khai. Đạt được sự thống nhất cuối cùng với nhóm về cấu trúc dự án. Triển khai \u0026amp; Tích hợp:\nTích hợp thành công các dịch vụ AWS cần thiết (ví dụ: Bedrock, Lambda, Database) vào ứng dụng cốt lõi. Triển khai dự án cuối cùng lên môi trường AWS. Thực hiện kiểm thử nghiêm ngặt sau triển khai và xử lý các lỗi tích hợp để đảm bảo tính ổn định. "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/1-worklog/1.12-week12/","title":"Worklog Tuần 12","tags":[],"description":"","content":"Mục tiêu Tuần 12: Hoàn thành và trau chuốt Internship Report. Xác định, debug (gỡ lỗi) và giải quyết tất cả các vấn đề còn tồn đọng trong giai đoạn deployment. Triển khai các tối ưu hóa hệ thống cuối cùng dựa trên sự đồng thuận của nhóm. Thực hiện buổi rà soát nội bộ cuối cùng và phiên trải nghiệm người dùng cho dự án cuối kỳ. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Viết báo cáo thực tập - Sửa những lỗi đã phát hiện trong quá trình triển khai dự án 24/11/2025 24/11/2025 3 - Tiếp tục tối ưu cho dự án - Meeting để thảo luận với nhóm về những lỗi trong quá trình làm việc gặp phải và cùng nhau đưa ra hướng giải quyết 25/11/2025 25/11/2025 4 - Hoàn thành hệ thống theo những giải pháp mà nhóm đã đề ra 26/11/2025 26/11/2025 5 - Hoàn thành hệ thống theo những giải pháp mà nhóm đã đề ra 27/11/2025 27/11/2025 6 - Hoàn thiện dự án - Meeting cùng nhau trải nghiệm sản phẩm của học kì này 28/08/2025 28/08/2025 Thành tựu Tuần 12: Tài liệu \u0026amp; Báo cáo:\nHoàn thành việc soạn thảo và biên tập Internship Report. Đảm bảo chất lượng (QA) \u0026amp; Debugging:\nĐã xác định thành công các lỗi (bugs) nghiêm trọng phát sinh từ đợt deployment ban đầu. Phối hợp với nhóm để thảo luận và thống nhất các giải pháp kỹ thuật hiệu quả. Hoàn thiện Hệ thống:\nTriển khai các giải pháp đã thống nhất, mang lại một hệ thống ổn định và được tối ưu hóa. Hệ thống hiện đã hoạt động đầy đủ chức năng và sẵn sàng cho việc nộp bài cuối cùng. Hoàn thành Sản phẩm:\nThực hiện thành công phiên demo/trải nghiệm sản phẩm \u0026ldquo;Cuối kỳ\u0026rdquo; với nhóm, xác nhận rằng tất cả các tính năng hoạt động như mong đợi. "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":" Blog 1 - Volkswagen và AWS đã xây dựng một quy trình MLOps hoàn chỉnh cho Nền Tảng Kỹ Thuật Số như thế nào Blog này chia sẻ câu chuyện thành công về sự hợp tác giữa Volkswagen và AWS trong việc xây dựng Nền Tảng Kỹ Thuật Số (Digital Production Platform - DPP). Bạn sẽ khám phá cách họ triển khai quy trình MLOps (Machine Learning Operations) toàn diện để tự động hóa và chuẩn hóa việc phát triển, triển khai và quản lý các mô hình học máy. Bài viết đi sâu vào các thách thức trong môi trường sản xuất công nghiệp, giải pháp kiến trúc để mở rộng quy mô, và cách quy trình này giúp Volkswagen tăng tốc độ đổi mới, tối ưu hóa hiệu quả vận hành trên toàn bộ chuỗi cung ứng toàn cầu.\nBlog 2 - Triển khai thử nghiệm khôi phục để xác thực phục hồi bằng AWS Backup Blog này nhấn mạnh rằng việc sao lưu dữ liệu thôi là chưa đủ; bạn cần phải đảm bảo dữ liệu đó có thể khôi phục được khi cần thiết. Bài viết hướng dẫn chi tiết cách sử dụng tính năng Restore Testing của AWS Backup để tự động hóa quy trình kiểm thử khôi phục. Bạn sẽ tìm hiểu cách thiết lập kế hoạch kiểm thử định kỳ, xác thực tính toàn vẹn của dữ liệu sau khi khôi phục, và tối ưu hóa chi phí. Đây là tài liệu quan trọng giúp các tổ chức đáp ứng các tiêu chuẩn tuân thủ (compliance) khắt khe và đảm bảo khả năng phục hồi sau thảm họa (Disaster Recovery).\nBlog 3 - Cải thiện hiệu suất PostgreSQL bằng cách sử dụng tiện ích mở rộng pgstattuple Blog này là một hướng dẫn kỹ thuật chuyên sâu về việc tối ưu hóa hiệu suất cho cơ sở dữ liệu PostgreSQL trên Amazon RDS và Aurora. Bạn sẽ được giới thiệu về tiện ích mở rộng pgstattuple – một công cụ mạnh mẽ giúp phân tích cấp độ lưu trữ vật lý của cơ sở dữ liệu. Bài viết giải thích các khái niệm về \u0026ldquo;dead tuples\u0026rdquo; và \u0026ldquo;table bloat\u0026rdquo; (sự phình to của bảng), cách sử dụng pgstattuple để chẩn đoán các vấn đề này, và các phương pháp hay nhất để dọn dẹp, bảo trì nhằm giữ cho cơ sở dữ liệu hoạt động với hiệu suất cao nhất.\n"},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/5-workshop/5.4-databaseandstorage/5.4.3-create-ecr/","title":"Tạo AWS ECR","tags":[],"description":"","content":" Mở Amazon Elastic Container Registry Trong màn hình tạo, nhập repository name Chọn Mutable cho Image tag mutability Sau đó nhấp Create "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/5-workshop/5.3-vpc/","title":"VPC","tags":[],"description":"","content":"Giới thiệu VPC (Virtual Private Cloud) là một không gian mạng ảo cô lập về mặt logic trong AWS Cloud. Nó hoạt động giống như một trung tâm dữ liệu cá nhân trên đám mây, cho phép bạn kiểm soát hoàn toàn môi trường mạng.\nThành phần lõi: Route Table Subnets Internet Gateway Security Groups Tạo VPC Mở Amazon VPC console Chọn Your VPCs, sau đó nhấp Create VPC Trong màn hình tạo VPC: Đặt tên trong Name tag: my-vpc-01 IPv4 CIDR: 10.0.0.0/16 Sau đó nhấp Create VPC Nội dung Create Route Table \u0026amp; Internet Gateway Create Subnets Create Security Groups Create VPC Endpoints "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/4-eventparticipated/","title":"Các events đã tham gia","tags":[],"description":"","content":"Trong quá trình thực tập, em đã tham gia 3 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là nhứng món quà và những khoảnh khắc rất tuyệt vời.\nEvent 1 Tên sự kiện: AWS Well-Architected Security Pillar\nThời gian: 09:00 ngày 29/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: DevOps trên AWS\nThời gian: 09:00 ngày 17/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 3 Tên sự kiện: AWS AI/ML và Generative AI Workshop\nThời gian: 09:00 ngày 15/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/5-workshop/5.4-databaseandstorage/","title":"Cơ sở dữ liệu và lưu trữ","tags":[],"description":"","content":"Tổng quan Dự án này sử dụng ba dịch vụ lưu trữ dữ liệu chính: AWS RDS (Relational Database Service): dịch vụ quản lý cơ sở dữ liệu, được đặt trong Private Subnet. AWS S3 (Simple Storage Service): lưu trữ hình ảnh và video. AWS ECR (Elastic Container Registry): lưu trữ Docker images. Nội dung Tạo RDS Tạo S3 Tạo ECR "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/5-workshop/5.5-computeandcontainer/","title":"Compute và Container","tags":[],"description":"","content":"IAM Role Tạo role ecsTaskExecutionRole cho AWS ECS (Elastic Container Service) để pull docker image và ghi log từ ECR repository Mở trang Amazon IAM Ở thanh điều hướng bên trái, chọn Roles, sau đó nhấp Create role Trong màn hình tạo, chọn AWS service và chọn Use case là EC2 rồi nhấp Next Ở bước Add permissions, tìm AmazonECSTaskExecutionRolePolicy và chọn policy này, rồi nhấp Next Ở phần Name, review, and create, đặt tên Role là ecsTaskExecutionRole, sau đó nhấp Create role Tạo role FargateTaskRole để cho phép Fargate truy cập tài nguyên Ở thanh điều hướng bên trái, chọn Roles, sau đó nhấp Create role Trong màn hình tạo, chọn AWS service và Use case là EC2 rồi nhấp Next Ở bước Add permissions, tìm và thêm AmazonS3FullAccess, AmazonSESFullAccess và AmazonSNSFullAccess, sau đó nhấp Next Review và đặt tên Role là FargateTaskRole, sau đó nhấp Create role ECS Cluster Tạo ECS Cluster để chạy Fargate Mở trang Amazon ECS Ở thanh điều hướng bên trái, chọn Clusters, sau đó nhấp Create Cluster Trong màn hình tạo, điền tên Cluster Ở phần Infrastructure, chọn Fargate only Sau đó nhấp Create Task definitions Tạo Task definition — định nghĩa container Ở thanh điều hướng của ECS console, chọn Task definitions, sau đó nhấp Create new task definitions Trong màn hình tạo, nhập Task definition family Chọn AWS Fargate trong phần Launch type của Infrastructure requirements Chọn Task role là FargateTaskRole Chọn Task execution role là ecsTaskExecutionRole Ở phần Container, nhập tên và URL của ECR, sau đó thêm Environment variable Kéo xuống cuối trang và nhấp Create ECS Service Tạo ECS Service để chạy Task definitions Ở thanh điều hướng bên trái, chọn Clusters, sau đó mở Cluster đã tạo Trong tab Services, nhấp Create Trong màn hình tạo, chọn Task definition family Chọn Task definition revision Điền tên Service Ở Compute options, chọn Capacity provider strategy Ở Capacity provider, chọn FARGATE Ở Platform version, chọn LATEST Ở Deployment configuration, chọn Scheduling strategy là Replica và Desired tasks = 1 Sau đó nhấp Create "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Triển khai hệ thống ReGenZet lên AWS Tổng quan ReGenZet là nền tảng quản lý gara xe điện cấp doanh nghiệp. Mục tiêu của workshop này là thiết kế và triển khai một hạ tầng đám mây trên AWS đảm bảo an toàn, tối ưu chi phí và tự động hóa cao để lưu trữ frontend, backend, lưu trữ media và các chức năng serverless AI/ML của ApexEV.\nNguyên tắc kiến trúc chính:\nAn ninh là ưu tiên: IAM theo nguyên tắc ít quyền nhất, mã hóa dữ liệu khi lưu và truyền, cô lập mạng và kiểm soát điểm truy cập dịch vụ. Tối ưu chi phí: sử dụng dịch vụ quản lý theo mô hình trả theo mức sử dụng, right-sizing và chính sách lifecycle tự động cho lưu trữ và compute. Tự động hóa \u0026amp; Quan sát: Infrastructure-as-Code, pipeline CI/CD, logging tập trung và cảnh báo tự động. Dịch vụ lõi sử dụng trong workshop:\nAWS ECS (Fargate) — chạy microservices backend mà không cần quản lý máy chủ. AWS Amplify — host frontend, cung cấp CI/CD cho client web và quản lý hosting. Amazon RDS — cơ sở dữ liệu quan hệ được quản lý cho dữ liệu giao dịch. Amazon S3 — lưu trữ đối tượng cho media, sao lưu và static assets. AWS Lambda — hàm serverless cho pipeline AI/ML, thông báo và tác vụ nền. Workshop này bao gồm các module thực hành bao quát toàn bộ stack và các best-practice cho từng lớp.\nNội dung Tổng quan Workshop Kiến trúc Dự án VPC của Dự án Cơ sở dữ liệu và Lưu trữ Compute và Container Tạo Load Balancer Tạo Amplify và API Gateway Hướng dẫn triển khai Frontend và Backend "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Trong quá trình thực tập tại [First Cloud Journey / AWS Study Group] từ ngày 15/09/2025 đến 28/11/2025, em đã có cơ hội quý báu để chuyển hóa kiến thức từ nhà trường vào môi trường làm việc thực tế, đặc biệt trong lĩnh vực Điện toán đám mây và Trí tuệ nhân tạo.\nem đã trực tiếp tham gia vào dự án \u0026ldquo;Phát triển Chatbot AI thông minh sử dụng AWS Bedrock và kiến trúc Serverless\u0026rdquo;. Thông qua dự án này, em đã nâng cao đáng kể kỹ năng về Hạ tầng Cloud (AWS VPC, EC2, Lambda), Xử lý ngôn ngữ tự nhiên (BERT, Transformers) và Tích hợp hệ thống Full-stack.\nVề thái độ làm việc, em luôn nỗ lực tiếp cận các công nghệ mới (GenAI, Serverless), tuân thủ tiến độ dự án và tích cực phối hợp với các mentor cũng như thành viên trong nhóm để tối ưu hóa kiến trúc hệ thống.\nĐể nhìn nhận lại quá trình thực tập một cách khách quan, em xin tự đánh giá bản thân dựa trên các tiêu chí sau:\nSTT Tiêu chí Mô tả Tốt Khá TB 1 Kiến thức \u0026amp; Kỹ năng chuyên môn Hiểu và vận dụng thành thạo các dịch vụ AWS, thuật toán NLP vào sản phẩm thực tế. ✅ ☐ ☐ 2 Khả năng học hỏi Thích nghi nhanh với các công nghệ mới (AWS Bedrock, Hugging Face) trong thời gian ngắn. ✅ ☐ ☐ 3 Tính chủ động Chủ động đề xuất thay đổi kiến trúc (Chuyển sang Serverless) để tối ưu hiệu năng. ✅ ☐ ☐ 4 Tinh thần trách nhiệm Đảm bảo đúng hạn các đầu việc quan trọng: Proposal, Thi giữa kỳ, và Triển khai cuối kỳ. ✅ ☐ ☐ 5 Tính kỷ luật Tuân thủ lịch trình làm việc, quy định báo cáo và nội quy tổ chức. ☐ ✅ ☐ 6 Tư duy cầu tiến Sẵn sàng tiếp thu phản hồi về Sơ đồ kiến trúc và thiết kế UI/UX để cải thiện sản phẩm. ✅ ☐ ☐ 7 Kỹ năng giao tiếp Trình bày rõ ràng các ý tưởng kỹ thuật trong báo cáo tuần và các buổi họp nhóm. ☐ ✅ ☐ 8 Kỹ năng làm việc nhóm Phối hợp nhịp nhàng với Front-end và Back-end để giải quyết xung đột tích hợp. ✅ ☐ ☐ 9 Tác phong chuyên nghiệp Tôn trọng đồng nghiệp, mentor và duy trì thái độ làm việc nghiêm túc. ✅ ☐ ☐ 10 Kỹ năng giải quyết vấn đề Xử lý các lỗi tích hợp (Debug) và tối ưu hóa độ trễ hệ thống trong giai đoạn kiểm thử. ☐ ✅ ☐ 11 Đóng góp cho dự án Hoàn thiện module AI và triển khai thành công hệ thống lên môi trường AWS. ✅ ☐ ☐ 12 Đánh giá chung Tổng kết lại toàn bộ quá trình thực tập. ✅ ☐ ☐ Các điểm cần cải thiện Tăng cường tính kỷ luật: Cần tuân thủ nghiêm ngặt hơn các quy trình làm việc và quản lý thời gian cá nhân để tránh tình trạng quá tải trong các giai đoạn nước rút (deployment). Nâng cao tư duy giải quyết vấn đề: Chuyển từ việc \u0026ldquo;sửa lỗi thụ động\u0026rdquo; sang \u0026ldquo;thiết kế phòng ngừa chủ động\u0026rdquo; để dự đoán và ngăn chặn lỗi hệ thống trước khi chúng xảy ra. Cải thiện kỹ năng giao tiếp: Cần trau dồi khả năng diễn đạt các giải pháp kỹ thuật phức tạp (như mô hình Transformer hay IAM Policies) một cách gãy gọn, dễ hiểu hơn trong các bối cảnh chuyên nghiệp. "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/5-workshop/5.8-instruct-deploy-be-fe/","title":"Hướng dẫn Deploy BackEnd And Frontend","tags":[],"description":"","content":"Triển khai Frontend Triển khai Frontend lên Amplify Mở terminal trong thư mục mã nguồn trên máy của bạn Commit và push lên branch đã được cấu hình trong Amplify Amplify sẽ tự động chạy CI/CD và triển khai Frontend Chờ khoảng 3–5 phút để quá trình hoàn tất Triển khai Backend Triển khai Backend lên Fargate Mở trang Amazon ECR Ở thanh điều hướng bên trái, chọn Repository và mở ECR repository đã tạo Mở terminal trong thư mục mã nguồn Backend trên máy của bạn Chạy aws configure để cấu hình Access Key và Secret Key cho tài khoản AWS Sau khi cấu hình CLI, quay lại trang console của ECR Repository Nhấp View push commands, bạn sẽ thấy các lệnh để push Docker image lên ECR Sao chép và dán các lệnh đó vào terminal của dự án Backend Sau khi hoàn tất các bước này, AWS ECS Fargate sẽ tự động pull và chạy image có tag latest. Chúc mừng — bạn đã hoàn thành workshop và triển khai thành công dự án lên AWS.\n"},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/5-workshop/5.7-amplifyandapigateway/","title":"Tạo Amplify và API Gateway","tags":[],"description":"","content":"AWS Amplify Tạo Amplify để triển khai Frontend Mở trang Amazon Amplify Nhấp Create new app Trong màn hình tạo, chọn GitLab, sau đó nhấp Next Ở bước Add repository and branch, đăng nhập vào GitLab, sau đó chọn repository và branch cần deploy Sau đó nhấp Next Cấu hình format theo loại mã nguồn frontend của bạn, sau đó nhấp Next Kiểm tra cấu hình và nhấp Save and deploy Sau bước này chờ khoảng 3–5 phút để deploy và bạn có thể truy cập ứng dụng từ internet API Gateway API Gateway là dịch vụ trung gian chuyển tiếp HTTP/HTTPS giữa Amplify (Frontend) và Fargate (Backend) Mở trang Amazon API Gateway Nhấp Create API Chọn REST API và nhấp Build Trong màn hình tạo, chọn API details là New API Điền tên API Chọn API endpoint type là Regional Chọn Security policy là SecurityPolicy_TLS13_1_2_2021_06 Sau đó nhấp Create API Ở thanh điều hướng bên trái, chọn APIs và mở API Gateway vừa tạo Ở giao diện API Gateway chọn Create Resource, điền Resource name và nhấp Create resource Ở resource console, nhấp Create method Trong Method details chọn ANY, và Integration type là HTTP Proxy Chọn HTTP method là ANY, và Endpoint URL là endpoint của ALB Sau đó kéo xuống cuối trang và nhấp Create method Trong resource proxy, tạo method Trong màn hình tạo, chọn Integration type là Mock và Method type là OPTIONS Sau đó nhấp Create method Hoàn tất cấu hình API Gateway cho dự án "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/5-workshop/5.6-createalb/","title":"Tạo AWS Load Balancers","tags":[],"description":"","content":" Mở trang Amazon EC2 Ở thanh điều hướng bên trái, chọn Load Balancers, sau đó nhấp Create load balancer Chọn Application Load Balancer Trong màn hình tạo, điền tên Load balancer Chọn Scheme là Internet-facing, sau đó chọn VPC Ở phần Availability Zones and subnets, chọn hai AZ và chọn hai subnet trong public Ở phần Security groups, chọn alb-sg Kéo xuống cuối trang và nhấp Create load balancer "},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":"Đánh giá chung 1. Môi trường làm việc Môi trường tại FCJ thực sự năng động và đậm chất công nghệ (\u0026ldquo;tech-driven\u0026rdquo;). Không khí làm việc luôn khuyến khích sự tò mò và đổi mới. Mình rất ấn tượng với cách mọi người thảo luận về các giải pháp kiến trúc (architecture solutions) – không có khoảng cách giữa \u0026ldquo;sếp\u0026rdquo; và thực tập sinh, tất cả đều tập trung vào việc tìm ra giải pháp tối ưu nhất cho bài toán.\n2. Sự hỗ trợ của mentor / team admin Mentor không chỉ là người hướng dẫn mà giống như một \u0026ldquo;Senior Cloud Engineer\u0026rdquo; đang kèm cặp đàn em. Khi mình gặp lỗi (ví dụ như không SSH được vào EC2 hay lỗi kết nối RDS), Mentor không sửa giúp ngay mà đưa ra các từ khóa, hướng dẫn cách đọc logs trong CloudWatch để mình tự debug. Cách này tuy lúc đầu hơi khó khăn nhưng giúp mình hiểu sâu vấn đề hơn rất nhiều. Team Admin cũng hỗ trợ nhiệt tình về tài khoản AWS lab để mình không bị gián đoạn khi thực hành.\n3. Sự phù hợp giữa công việc và chuyên ngành học Là sinh viên chuyên ngành CNTT, việc tham gia FCJ như một mảnh ghép hoàn hảo để biến lý thuyết \u0026ldquo;Mạng máy tính\u0026rdquo; và \u0026ldquo;Hệ điều hành\u0026rdquo; thành thực tế. Những khái niệm trừu tượng như IP, Subnet mask giờ đây hiện hữu rõ ràng thông qua việc cấu hình VPC trên AWS. Đây là bước đệm vững chắc cho định hướng kỹ sư hệ thống/DevOps của mình.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng Đây là phần mình tâm đắc nhất. Từ một người mơ hồ về Cloud, mình đã nắm vững được các dịch vụ cốt lõi của AWS:\nEC2 (Elastic Compute Cloud): Mình đã biết cách khởi tạo máy chủ ảo, lựa chọn instance type phù hợp và quản lý Security Group. VPC (Virtual Private Cloud): Hiểu sâu về kiến trúc mạng, cách chia Private/Public Subnet, cấu hình Route Table và Internet Gateway. S3 (Simple Storage Service): Học cách lưu trữ static website và quản lý quyền truy cập bucket policy. IAM (Identity and Access Management): Hiểu tầm quan trọng của nguyên tắc \u0026ldquo;least privilege\u0026rdquo; khi phân quyền cho user và role. RDS (Relational Database Service): Biết cách triển khai cơ sở dữ liệu trên cloud và kết nối an toàn với backend. 5. Văn hóa \u0026amp; tinh thần đồng đội Văn hóa \u0026ldquo;Share to learn\u0026rdquo; (Chia sẻ để học hỏi) được thể hiện rất rõ. Mỗi tuần team đều có các buổi tech-talk nhỏ để chia sẻ về những dịch vụ mới hoặc những case study khó. Tinh thần đồng đội lên cao nhất là khi cả nhóm cùng nhau \u0026ldquo;troubleshoot\u0026rdquo; một lỗi deploy đến tận tối muộn nhưng ai cũng vui vẻ khi hệ thống chạy thành công (Status check: 2/2 passed).\n6. Chính sách / phúc lợi cho thực tập sinh Ngoài phụ cấp, cái \u0026ldquo;lời\u0026rdquo; nhất của mình là được cấp quyền truy cập vào môi trường Sandbox của AWS để vọc vạch mà không sợ bị \u0026ldquo;bill shock\u0026rdquo;. Các resources tài liệu nội bộ và các buổi workshop training cũng là những phúc lợi kiến thức vô giá.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập? Đó là cảm giác \u0026ldquo;vỡ òa\u0026rdquo; khi tự tay mình triển khai thành công một kiến trúc 3-tier (3 lớp) hoàn chỉnh trên AWS, từ Load Balancer trỏ vào Auto Scaling Group cho đến Database nằm trong Private Subnet. Nó chứng minh rằng kiến thức mình học được là thực tế và dùng được ngay.\nĐiều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau? Mình nghĩ chương trình có thể bổ sung thêm các bài lab về Infrastructure as Code (như Terraform hoặc CloudFormation) sớm hơn một chút, vì việc click tay trên Console tuy trực quan nhưng khá tốn thời gian khi làm lại nhiều lần.\nNếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao? Chắc chắn là CÓ. FCJ là môi trường lý tưởng cho những bạn muốn bắt đầu sự nghiệp Cloud/DevOps. Bạn sẽ không bị giao những việc vặt vãnh mà sẽ được \u0026ldquo;nhúng\u0026rdquo; mình vào các dự án và công nghệ thực tế.\nĐề xuất \u0026amp; mong muốn Nên có thêm các buổi \u0026ldquo;Mock Interview\u0026rdquo; hoặc định hướng thi chứng chỉ AWS (như SAA-C03) vào cuối kỳ thực tập để các bạn tự tin hơn khi apply chính thức.\nMình rất mong muốn được tiếp tục đồng hành cùng FCJ, có thể là ở vị trí Fresher hoặc Junior Cloud Engineer để tiếp tục chinh phục các dịch vụ nâng cao hơn như EKS hay Serverless.\nCảm ơn team FCJ đã kiên nhẫn và tạo điều kiện cho mình sai để sửa. Đây là một hành trình thực sự đáng nhớ!\n"},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://phucthichnghiccode.github.io/InternshipReport.github.io/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]